{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "import requests\n",
        "import pyspark.sql.functions as f\n",
        "import json\n",
        "import re\n",
        "\n",
        "class OpenAPIUtil:\n",
        "    \"\"\"\n",
        "    A Utility class to help processing transformations using Open API (Swagger).\n",
        "\n",
        "    Parameters:\n",
        "        1) swagger_url: URL to the OpenAPI Swaggern endpoint\n",
        "\n",
        "    Methods:\n",
        "        1) create_spark_schemas(): returns a dictionary of Spark schemas of all endpoints with entity name as the Key.\n",
        "        2) create_metadata(): returns list of dictionaries containing metadata of each field in every endpoint.\n",
        "        3) write_oea_metadata(destination_path): Writes out the OEA Metadata CSV file at the destination directory.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, swagger_url):\n",
        "        self.swagger_json = json.loads(requests.get(swagger_url).text)\n",
        "        self.metadata_headers = ['table_name', 'column_name', 'type', 'format', 'maxLength', 'required', 'items', '$ref', 'pseudonymization']\n",
        "        self.definitions = {}\n",
        "        self.metadata = {}\n",
        "        self.tables = []\n",
        "        self.schemas = {}\n",
        "        self.dependency_dict = {}\n",
        "        self.dependency_order = []\n",
        "        self.visited = {}\n",
        "\n",
        "    def get_reference(self, row):\n",
        "        if(row['type'] == 'array'):\n",
        "            reference = row['items']['$ref']\n",
        "        elif(row['$ref'] != None):\n",
        "           reference = row['$ref']\n",
        "        else:\n",
        "            return None\n",
        "        return reference.split('/')[-1].split('_')[-1]\n",
        "\n",
        "    def pluralize(self, noun):\n",
        "        if noun == 'person' : return 'people'\n",
        "        if noun == 'survey' : return 'surveys'\n",
        "        if re.search('[sxz]$', noun):\n",
        "            return re.sub('$', 'es', noun)\n",
        "        if re.search('y$', noun):\n",
        "            return re.sub('y$', 'ies', noun)\n",
        "        return noun + 's'\n",
        "\n",
        "    def get_data_type(self, dtype, format):\n",
        "        if(dtype == 'string'):\n",
        "            if(format == 'date'):\n",
        "                return DateType()\n",
        "            if(format == 'date-time'):\n",
        "                return TimestampType()\n",
        "            return StringType()\n",
        "        if(dtype == 'integer'):\n",
        "            return IntegerType()\n",
        "        if(dtype == 'number'):\n",
        "            return DecimalType()\n",
        "        if(dtype == 'boolean'):\n",
        "            return BooleanType()\n",
        "\n",
        "    def create_definitions(self):\n",
        "        for entity in self.swagger_json['definitions']:\n",
        "            properties = self.swagger_json['definitions'][entity]['properties']\n",
        "            table_name = entity.split('_')[-1]\n",
        "            table_schema = {}\n",
        "\n",
        "            for prop in properties:\n",
        "                if 'description' in properties[prop].keys():\n",
        "                    properties[prop].pop('description')\n",
        "                field_info = properties[prop]\n",
        "                if 'required' in self.swagger_json['definitions'][entity].keys():\n",
        "                    field_info['required'] = True if prop in self.swagger_json['definitions'][entity]['required'] else False\n",
        "                else:\n",
        "                    field_info['required'] = False\n",
        "                field_info['table_name'] = entity.split('_')[-1]\n",
        "                field_info['column_name'] = prop\n",
        "                if 'x-Ed-Fi-pseudonymization' in field_info:\n",
        "                    field_info['pseudonymization'] = field_info['x-Ed-Fi-pseudonymization']\n",
        "                    field_info.pop('x-Ed-Fi-pseudonymization')\n",
        "                for header in [x for x in self.metadata_headers if x not in field_info] : field_info[header] = None\n",
        "                table_schema[prop] = field_info\n",
        "\n",
        "            self.definitions[table_name] = table_schema\n",
        "        self.tables = [x for x in self.definitions.keys()]\n",
        "\n",
        "    def create_metadata(self):\n",
        "        if(len(self.schemas) == 0):\n",
        "            self.create_spark_schemas()\n",
        "        for table_name in self.dependency_order:\n",
        "            table_metadata = []\n",
        "            for col_name in self.definitions[table_name]:\n",
        "                col_schema = self.definitions[table_name][col_name]\n",
        "                key = self.pluralize(table_name)\n",
        "\n",
        "                if 'x-Ed-Fi-fields-to-pluck' in col_schema and col_schema['x-Ed-Fi-fields-to-pluck'] != [\"*\"]:\n",
        "                    referenced_table = self.get_reference(col_schema)\n",
        "                    table_metadata += [x for x in self.metadata[self.pluralize(referenced_table)] if x[0] in col_schema['x-Ed-Fi-fields-to-pluck']]\n",
        "\n",
        "                elif 'x-Ed-Fi-explode' in col_schema and col_schema['x-Ed-Fi-explode']:\n",
        "                    referenced_table = self.get_reference(col_schema)\n",
        "                    table_metadata += self.metadata[self.pluralize(referenced_table)]\n",
        "\n",
        "                else:\n",
        "                    op = self.definitions[table_name][col_name]['pseudonymization']\n",
        "                    if op == None: op = 'no-op'\n",
        "                    table_metadata.append([col_name, self.schemas[key][col_name].dataType.typeName(), op])\n",
        "            self.metadata[self.pluralize(table_name)] = table_metadata\n",
        "        return self.metadata\n",
        "\n",
        "    def write_oea_metadata(self, destination_path):\n",
        "        if(self.metadata == []):\n",
        "            self.create_metadata()\n",
        "        oea_metadata = []\n",
        "        for table_name in self.metadata:\n",
        "            oea_metadata.append([table_name, None, None, None])\n",
        "            for col_metadata in self.metadata[table_name]:\n",
        "                oea_metadata.append([None] + col_metadata)\n",
        "        metadata_df = spark.createDataFrame(oea_metadata, ['Entity Name','Attribute Name','Attribute Data Type','Pseudonymization'])\n",
        "        metadata_df.coalesce(1).write.format('csv').save(destination_path)\n",
        "\n",
        "    def create_dependency_dict(self):\n",
        "        for table_name in self.definitions:\n",
        "            for column_name in self.definitions[table_name]:\n",
        "                column_info = self.definitions[table_name][column_name]\n",
        "                referenced_table = self.get_reference(column_info)\n",
        "                if(referenced_table is None):\n",
        "                    continue\n",
        "                if table_name not in self.dependency_dict:\n",
        "                    self.dependency_dict[table_name] = [referenced_table]\n",
        "                elif referenced_table not in self.dependency_dict[table_name]:\n",
        "                    self.dependency_dict[table_name].append(referenced_table)\n",
        "\n",
        "    def dfs(self, table_name):\n",
        "        self.visited[table_name] = True\n",
        "        if table_name not in self.dependency_dict:\n",
        "            self.dependency_order.append(table_name)\n",
        "            return\n",
        "\n",
        "        for dependent_table in self.dependency_dict[table_name]:\n",
        "            if(self.visited[dependent_table] is False):\n",
        "                self.dfs(dependent_table)\n",
        "            if(self.visited[dependent_table] is False):\n",
        "                self.dependency_order.append(dependent_table)\n",
        "\n",
        "        self.dependency_order.append(table_name)\n",
        "\n",
        "    def create_dependency_order(self):\n",
        "        for table_name in self.tables:\n",
        "            self.visited[table_name] = False\n",
        "        for table_name in self.tables:\n",
        "            if(self.visited[table_name] is False):\n",
        "                self.dfs(table_name)\n",
        "\n",
        "    def create_spark_schemas_from_definitions(self):\n",
        "        for entity in self.dependency_order:\n",
        "            table_schema = self.definitions[entity]\n",
        "            spark_schema = []\n",
        "            if(entity == 'localEducationAgencyReference'):\n",
        "                print(entity)\n",
        "            for col_name in table_schema:\n",
        "                col_metadata = {}\n",
        "                if('pseudonymization' in table_schema[col_name]): col_metadata['pseudonymization'] = table_schema[col_name]['pseudonymization']\n",
        "                if('x-Ed-Fi-isIdentity' in table_schema[col_name]): col_metadata['x-Ed-Fi-isIdentity'] = table_schema[col_name]['x-Ed-Fi-isIdentity']\n",
        "                \n",
        "                col_metadata['required'] = table_schema[col_name]['required']\n",
        "                referenced_table = self.get_reference(table_schema[col_name])\n",
        "                if table_schema[col_name]['type'] == 'array':\n",
        "                    datatype = ArrayType(self.schemas[self.pluralize(referenced_table)])\n",
        "                    col_metadata['x-Ed-Fi-explode'] = table_schema[col_name]['x-Ed-Fi-explode']\n",
        "                elif table_schema[col_name]['$ref'] != None:\n",
        "                    datatype = self.schemas[self.pluralize(referenced_table)]\n",
        "                    if('x-Ed-Fi-fields-to-pluck' in table_schema[col_name]):\n",
        "                        col_metadata['x-Ed-Fi-fields-to-pluck'] = table_schema[col_name]['x-Ed-Fi-fields-to-pluck']\n",
        "                else:\n",
        "                    datatype = self.get_data_type(table_schema[col_name]['type'], table_schema[col_name]['format'])\n",
        "                col_spark_schema = StructField(col_name, datatype, not(table_schema[col_name]['required']))\n",
        "                col_spark_schema.metadata = col_metadata\n",
        "                spark_schema.append(col_spark_schema)\n",
        "            self.schemas[self.pluralize(entity)] = StructType(spark_schema)\n",
        "\n",
        "    def create_spark_schemas(self):\n",
        "        if(len(self.schemas) == 0):\n",
        "            self.create_definitions()\n",
        "            self.create_dependency_dict()\n",
        "            self.create_dependency_order()\n",
        "            self.create_spark_schemas_from_definitions()\n",
        "        return self.schemas"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('Spark_Dev')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "be620d6548581d4b255e22136663c988a2c6aa20c2fcc1339f2748495f9e98b2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
