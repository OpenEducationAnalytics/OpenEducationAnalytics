{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\r\n",
        "\"\"\"\r\n",
        "Provides data processing methods for Community Brands Xporter data.\r\n",
        "Data is expected to be received via Xporter into oea/Transactional\r\n",
        "The structure of the folders in oea(Primary) will then be something like:\r\n",
        "    -> oea/transactional/xporter/[EstabId]\r\n",
        "        ->  oea/transactional/xporter/[EstabId]/Schoolinfo.json\r\n",
        "        -> oea/transactional/xporter/[EstabId]/Students.json\r\n",
        "        etc\r\n",
        "In stage1, everything is written to stage1/Transactional/xporter and stage2/[Ingested/refined]/xporter\r\n",
        "\"\"\"\r\n",
        "class Xporter():\r\n",
        "    def __init__(self, source_folder='xporter', pseudonymize = True):\r\n",
        "        self.set_oea_workspace('prod')\r\n",
        "        self.schemas = {}\r\n",
        "        self.schemas['schoolinfo'] = [\r\n",
        "                                        ['CurrentAcademicYear', 'string', 'no-op'],\r\n",
        "                                        ['DeniNo', 'string', 'no-op'],\r\n",
        "                                        ['Email', 'string', 'no-op'],\r\n",
        "                                        ['EstabId', 'string', 'no-op'],\r\n",
        "                                        ['ExamCentre', 'string', 'no-op'],\r\n",
        "                                        ['Governance', 'string', 'no-op'],\r\n",
        "                                        ['Head', 'string', 'no-op'],\r\n",
        "                                        ['Id', 'string', 'no-op'],\r\n",
        "                                        ['LastUpdated', 'string', 'no-op'],\r\n",
        "                                        ['MainContact', 'string', 'no-op'],\r\n",
        "                                        ['Name', 'string', 'no-op'],\r\n",
        "                                        ['Phase', 'string', 'no-op'],\r\n",
        "                                        ['RowHash', 'string', 'mask'],\r\n",
        "                                        ['SchoolLogoAlternateUrl', 'string', 'no-op'],\r\n",
        "                                        ['SchoolLogoUrl', 'string', 'no-op'],\r\n",
        "                                        ['Telephone', 'string', 'no-op'],\r\n",
        "                                        ['Web', 'string', 'no-op'],\r\n",
        "                                        ['SchoolKey', 'string', 'no-op'],\r\n",
        "                                        ['SchoolID', 'string', 'hash'],\r\n",
        "                                        ['Address', 'string', 'no-op']]\r\n",
        "\r\n",
        "        self.schemas['students'] = [    ['AdmissionNo', 'string', 'no-op'],\r\n",
        "                                        ['Apartment', 'string', 'no-op'],\r\n",
        "                                        ['AsylumStatus', 'string', 'no-op'],\r\n",
        "                                        ['AttMarksEndDate', 'string', 'no-op'],\r\n",
        "                                        ['AttMarksStartDate', 'string', 'no-op'],\r\n",
        "                                        ['Boarder', 'string', 'no-op'],\r\n",
        "                                        ['BoardingHouse', 'string', 'no-op'],\r\n",
        "                                        ['CandidateNo', 'string', 'no-op'],\r\n",
        "                                        ['Country', 'string', 'no-op'],\r\n",
        "                                        ['CountryOfBirth', 'string', 'no-op'],\r\n",
        "                                        ['CountryOfBirthCode', 'string', 'no-op'],\r\n",
        "                                        ['County', 'string', 'no-op'],\r\n",
        "                                        ['DateofBirth', 'string', 'mask'],\r\n",
        "                                        ['Destination', 'string', 'no-op'],\r\n",
        "                                        ['DestinationStartDate', 'string', 'no-op'],\r\n",
        "                                        ['Disabled', 'string', 'no-op'],\r\n",
        "                                        ['DisplayName', 'string', 'no-op'],\r\n",
        "                                        ['District', 'string', 'no-op'],\r\n",
        "                                        ['EAL', 'string', 'no-op'],\r\n",
        "                                        ['EnglishProficiencyLevel', 'string', 'no-op'],\r\n",
        "                                        ['EnglishProficiencyLevelCode', 'string', 'no-op'],\r\n",
        "                                        ['EnrolmentStatus', 'string', 'no-op'],\r\n",
        "                                        ['EntryDate', 'string', 'no-op'],\r\n",
        "                                        ['Ethnicity', 'string', 'no-op'],\r\n",
        "                                        ['EthnicityCode', 'string', 'no-op'],\r\n",
        "                                        ['EthnicitySource', 'string', 'no-op'],\r\n",
        "                                        ['EverInCare', 'string', 'no-op'],\r\n",
        "                                        ['ExternalId', 'string', 'no-op'],\r\n",
        "                                        ['FSMEver6', 'string', 'no-op'],\r\n",
        "                                        ['FirstLanguage', 'string', 'no-op'],\r\n",
        "                                        ['FirstLanguageCode', 'string', 'no-op'],\r\n",
        "                                        ['FirstLanguageSource', 'string', 'no-op'],\r\n",
        "                                        ['Forename', 'string', 'no-op'],\r\n",
        "                                        ['FsmEligible', 'string', 'no-op'],\r\n",
        "                                        ['FsmStartDate', 'string', 'no-op'],\r\n",
        "                                        ['FsmEndDate', 'string', 'no-op'],\r\n",
        "                                        ['Gender', 'string', 'no-op'],\r\n",
        "                                        ['Gifted', 'string', 'no-op'],\r\n",
        "                                        ['HomeLanguage', 'string', 'no-op'],\r\n",
        "                                        ['HomeLanguageCode', 'string', 'no-op'],\r\n",
        "                                        ['HouseGroup', 'string', 'no-op'],\r\n",
        "                                        ['HouseGroupId', 'string', 'no-op'],\r\n",
        "                                        ['HouseName', 'string', 'no-op'],\r\n",
        "                                        ['HouseNo', 'string', 'no-op'],\r\n",
        "                                        ['Id', 'string', 'no-op'],\r\n",
        "                                        ['IdaasEmail', 'string', 'no-op'],\r\n",
        "                                        ['IdaasId', 'string', 'no-op'],\r\n",
        "                                        ['InLeaCare', 'string', 'no-op'],\r\n",
        "                                        ['IsTraveller', 'string', 'no-op'],\r\n",
        "                                        ['IsYoungCarer', 'string', 'no-op'],\r\n",
        "                                        ['KeyStage', 'string', 'no-op'],\r\n",
        "                                        ['LastUpdated', 'string', 'no-op'],\r\n",
        "                                        ['LeaCareAuthority', 'string', 'no-op'],\r\n",
        "                                        ['LeavingDate', 'string', 'no-op'],\r\n",
        "                                        ['LeavingRegGroup', 'string', 'no-op'],\r\n",
        "                                        ['LeavingYearGroup', 'string', 'no-op'],\r\n",
        "                                        ['LegalForename', 'string', 'no-op'],\r\n",
        "                                        ['LegalSurname', 'string', 'no-op'],\r\n",
        "                                        ['Marks', 'string', 'no-op'],\r\n",
        "                                        ['MiddleName', 'string', 'no-op'],\r\n",
        "                                        ['ModeOfTravel', 'string', 'no-op'],\r\n",
        "                                        ['NCYear', 'string', 'no-op'],\r\n",
        "                                        ['NationalIdentity', 'string', 'no-op'],\r\n",
        "                                        ['Nationality', 'string', 'no-op'],\r\n",
        "                                        ['OnReport', 'string', 'no-op'],\r\n",
        "                                        ['ParentalSalutation', 'string', 'no-op'],\r\n",
        "                                        ['PartTime', 'string', 'no-op'],\r\n",
        "                                        ['PostCode', 'string', 'no-op'],\r\n",
        "                                        ['PreviousLegalSurname', 'string', 'no-op'],\r\n",
        "                                        ['PupilPremium', 'string', 'no-op'],\r\n",
        "                                        ['QuickNote', 'string', 'no-op'],\r\n",
        "                                        ['ReasonForLeaving', 'string', 'no-op'],\r\n",
        "                                        ['RegGroup', 'string', 'no-op'],\r\n",
        "                                        ['RegGroupId', 'string', 'no-op'],\r\n",
        "                                        ['Religion', 'string', 'no-op'],\r\n",
        "                                        ['ReligionCode', 'string', 'no-op'],\r\n",
        "                                        ['RowHash', 'string', 'no-op'],\r\n",
        "                                        ['SENProvision', 'string', 'no-op'],\r\n",
        "                                        ['ServiceChild', 'string', 'no-op'],\r\n",
        "                                        ['ServiceChildSource', 'string', 'no-op'],\r\n",
        "                                        ['StandardYearGroupCode', 'string', 'no-op'],\r\n",
        "                                        ['StandardYearGroupName', 'string', 'no-op'],\r\n",
        "                                        ['Street', 'string', 'no-op'],\r\n",
        "                                        ['StudentStatus', 'string', 'no-op'],\r\n",
        "                                        ['Surname', 'string', 'no-op'],\r\n",
        "                                        ['TownOrCity', 'string', 'no-op'],\r\n",
        "                                        ['TravellerSource', 'string', 'no-op'],\r\n",
        "                                        ['UPN', 'string', 'no-op'],\r\n",
        "                                        ['UniformAllowance', 'string', 'no-op'],\r\n",
        "                                        ['UniqueLearnerNumber', 'string', 'no-op'],\r\n",
        "                                        ['WorkEmail', 'string', 'no-op'],\r\n",
        "                                        ['XID', 'string', 'no-op'],\r\n",
        "                                        ['YSSA', 'string', 'no-op'],\r\n",
        "                                        ['YearGroup', 'string', 'no-op'],\r\n",
        "                                        ['YearGroupId', 'string', 'no-op'],\r\n",
        "                                        ['YearTaughtIn', 'string', 'no-op'],\r\n",
        "                                        ['formerUPN', 'string', 'no-op'],\r\n",
        "                                        ['SchoolID', 'string', 'no-op'],\r\n",
        "                                        ['AddressBlock', 'string', 'no-op'],\r\n",
        "                                        ['UniqueStudentId', 'string', 'hash']\r\n",
        "                                        ] \r\n",
        "\r\n",
        "\r\n",
        "        self.schemas['attendancesummary'] = [['Id', 'string', 'no-op'],\r\n",
        "                                            ['XID', 'string', 'no-op'],\r\n",
        "                                            ['MIS_ID', 'string', 'no-op'],\r\n",
        "                                            ['IdaasId', 'string', 'no-op'],\r\n",
        "                                            ['AttStatsStartDate', 'string', 'no-op'],\r\n",
        "                                            ['AttStatsEndDate', 'string', 'no-op'],\r\n",
        "                                            ['NumPossMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumPresMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumAEAMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumAuthAbsMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumUnauthAbsMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumMissMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumLateMarks', 'string', 'no-op'],\r\n",
        "                                            ['NumLateBeforeRegMarks', 'string', 'no-op'],\r\n",
        "                                            ['Marks', 'string', 'mask'],\r\n",
        "                                            ['UniqueAttendanceId', 'string', 'hash'],\r\n",
        "                                            ['SchoolID', 'string', 'no-op']] \r\n",
        "\r\n",
        "        self.schemas['groups'] = [['Code', 'string', 'no-op'],\r\n",
        "                                ['ExternalId', 'string', 'no-op'],\r\n",
        "                                ['Id', 'string', 'no-op'],\r\n",
        "                                ['IdaasId', 'string', 'no-op'],\r\n",
        "                                ['LastUpdated', 'string', 'no-op'],\r\n",
        "                                ['Name', 'string', 'no-op'],\r\n",
        "                                ['NumStudents', 'string', 'no-op'],\r\n",
        "                                ['PlatformId', 'string', 'no-op'],\r\n",
        "                                ['PrimaryStaffId', 'string', 'no-op'],\r\n",
        "                                ['RowHash', 'string', 'mask'],\r\n",
        "                                ['Staff', 'string', 'no-op'],\r\n",
        "                                ['Type', 'string', 'no-op'],\r\n",
        "                                ['XID', 'string', 'no-op'],\r\n",
        "                                ['SchoolID', 'string', 'no-op'],\r\n",
        "                                ['UniqueGroupId', 'string', 'hash']] \r\n",
        "\r\n",
        "        self.schemas['HistoricalAttendanceSummary'] = [['EndDate', 'string', 'no-op'],\r\n",
        "                                                ['Id','string', 'no-op'],\r\n",
        "                                                ['SchoolYear', 'string', 'no-op'],\r\n",
        "                                                ['StartDate', 'string', 'no-op'],\r\n",
        "                                                ['StudentId', 'string', 'no-op'],\r\n",
        "                                                ['SchoolID', 'string', 'no-op'],\r\n",
        "                                                ['UniqueHistoricalAttendanceId', 'string', 'hash'],\r\n",
        "                                                ['Marks', 'string', 'no-op']]\r\n",
        "\r\n",
        "        self.schemas['staff'] = [[\"Apartment\",\"string\", 'no-op'],\r\n",
        "                                [\"Country\",\"string\", 'no-op'],\r\n",
        "                                [\"County\",\"string\", 'no-op'],\r\n",
        "                                [\"DateOfBirth\", \"string\", 'no-op'],\r\n",
        "                                [\"DisplayName\", 'string', 'no-op'],\r\n",
        "                                [\"District\",\"string\", 'no-op'],\r\n",
        "                                [\"EmploymentEnd\",\"string\", 'no-op'],\r\n",
        "                                [\"EmploymentStart\", 'string', 'no-op'],\r\n",
        "                                [\"ExternalId\",\"string\", 'no-op'],\r\n",
        "                                [\"Forename\",\"string\", 'no-op'],\r\n",
        "                                [\"Gender\",\"string\", 'no-op'],\r\n",
        "                                [\"HomeEmail\", 'string', 'no-op'],\r\n",
        "                                [\"HomePhone\", 'string', 'no-op'],\r\n",
        "                                [\"HouseName\", 'string', 'no-op'],\r\n",
        "                                [\"HouseNo\", 'string', 'no-op'],\r\n",
        "                                [\"Id\", 'string', 'no-op'],\r\n",
        "                                [\"IdaasEmail\", \"string\", 'no-op'],\r\n",
        "                                [\"IdaasId\", \"string\", 'no-op'],\r\n",
        "                                [\"IsSupply\", \"string\", 'no-op'],\r\n",
        "                                [\"IsSupport\", 'string', 'no-op'],\r\n",
        "                                [\"IsTeacher\", \"string\", 'no-op'],\r\n",
        "                                [\"LastUpdated\", \"string\", 'no-op'],\r\n",
        "                                [\"LegalForename\", \"string\", 'no-op'],\r\n",
        "                                [\"LegalSurname\", 'string', 'no-op'],\r\n",
        "                                [\"MiddleName\", \"string\", 'no-op'],\r\n",
        "                                [\"MobilePhone\", \"string\", 'no-op'],\r\n",
        "                                [\"NINumber\", \"string\", 'no-op'],\r\n",
        "                                [\"PayrollNumber\", \"string\", 'no-op'],\r\n",
        "                                [\"PostCode\", 'string', 'no-op'],\r\n",
        "                                [\"RegGroup\", \"string\", 'no-op'],\r\n",
        "                                [\"RoleCodes\", \"string\", 'no-op'],\r\n",
        "                                [\"Roles\", 'string', 'no-op'],\r\n",
        "                                [\"RowHash\", 'string', 'mask'],\r\n",
        "                                [\"StaffCode\", \"string\", 'no-op'],\r\n",
        "                                [\"StaffStatus\", 'string', 'no-op'],\r\n",
        "                                [\"Street\", \"string\", 'no-op'],\r\n",
        "                                [\"Suffix\", 'string', 'no-op'],\r\n",
        "                                [\"Surname\", \"string\", 'no-op'],\r\n",
        "                                [\"TeacherCategory\", \"string\", 'no-op'],\r\n",
        "                                [\"TeacherNumber\", 'string', 'no-op'],\r\n",
        "                                [\"Title\", 'string', 'no-op'],\r\n",
        "                                [\"TownOrCity\", 'string', 'no-op'],\r\n",
        "                                [\"WorkEmail\", 'string', 'no-op'],\r\n",
        "                                [\"WorkPhone\", \"string\", 'no-op'],\r\n",
        "                                [\"XID\", \"string\", 'no-op'],\r\n",
        "                                ['SchoolID', 'string', 'no-op'],\r\n",
        "                                ['UniqueStaffId','string','hash'],\r\n",
        "                                [\"AddressBlock\",'string', 'no-op']]\r\n",
        "\r\n",
        "\r\n",
        "        self.schemas['StudentMembers'] = [['EndDate', 'string', 'no-op'],\r\n",
        "                                        ['GroupExternalId', 'string', 'no-op'],\r\n",
        "                                        ['GroupId', 'string', 'no-op'],\r\n",
        "                                        ['GroupIdaasId', 'string', 'no-op'],\r\n",
        "                                        ['Id', 'string', 'no-op'],\r\n",
        "                                        ['LastUpdated', 'string', 'no-op'],\r\n",
        "                                        ['RowHash', 'string', 'mask'],\r\n",
        "                                        ['StartDate', 'string', 'no-op'],\r\n",
        "                                        ['StudentExternalId', 'string', 'no-op'],\r\n",
        "                                        ['StudentId', 'string', 'no-op'],\r\n",
        "                                        ['StudentIdaasId', 'string', 'no-op'],\r\n",
        "                                        ['SchoolID', 'string', 'no-op'],\r\n",
        "                                        ['UniqueStudentId', 'string', 'no-op'],\r\n",
        "                                        ['UniqueGroupId', 'string', 'no-op'],\r\n",
        "                                        ['UniqueStudentMemberId', 'string', 'hash']]\r\n",
        " \r\n",
        "    def set_oea_workspace(self, workspace_name):\r\n",
        "        oea.set_workspace(workspace_name)\r\n",
        "    \r\n",
        "    def json_from_xporter(self, source_path, multiline):\r\n",
        "        print(source_path)\r\n",
        "        options = {'format':'json', 'multiline':multiline}\r\n",
        "        df = spark.read.load(source_path, **options)\r\n",
        "        return df\r\n",
        "   \r\n",
        "    def get_oea_path(self):\r\n",
        "        return 'abfss://oea@' + oea.storage_account + '.dfs.core.windows.net'\r\n",
        "\r\n",
        "    def land_to_stage3(self, data, entity_path, filename):\r\n",
        "        sink_path = f'stage3/Transactional/{entity_path}/{filename}'\r\n",
        "        oea.write(data, sink_path)\r\n",
        "        return sink_path\r\n",
        "\r\n",
        "    def overwrite_to_path(self, df, destination_path, save_format = \"parquet\", primary_key='id'):\r\n",
        "        destination_url = oea.to_url(destination_path)\r\n",
        "        df = df.dropDuplicates([primary_key])\r\n",
        "        df.write.format(save_format).mode('overwrite').save(destination_url)\r\n",
        "\r\n",
        "    def _prepare_schoolinfo(self):\r\n",
        "        from pyspark.sql.functions import lit\r\n",
        "        #oea.rm_if_exists(oea.stage1np + '/xporter/schoolinfocsv')\r\n",
        "        df_schoolinfo = None\r\n",
        "        # loop through school EstabId folders landed by Xporter and union schoolinfo\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            if folder.isnumeric():\r\n",
        "                print(folder)\r\n",
        "                try:\r\n",
        "                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/SchoolInfo*'\r\n",
        "                    print(xporterPath)\r\n",
        "                    df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    df.show()\r\n",
        "                    dfc = df.select(F.explode('SchoolInfo').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    dfc.show()\r\n",
        "                    dfc = dfc.drop('Address')\r\n",
        "                    newdf = dfc.withColumn(\"Address\",col(\"RowHash\"))\r\n",
        "                    newdf = newdf.withColumn('SchoolID',lit(folder))\r\n",
        "                    newdf = newdf.withColumn('SchoolKey',lit(folder))\r\n",
        "                    if df_schoolinfo is None:\r\n",
        "                        df_schoolinfo = newdf\r\n",
        "                    else:\r\n",
        "                        df_schoolinfo = df_schoolinfo.union(newdf)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "        \r\n",
        "        csvString = df_schoolinfo.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/SchoolInfo', 'SchoolInfo.csv', oea.DELTA_BATCH_DATA)\r\n",
        "\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/SchoolInfo')\r\n",
        "        display(df)        \r\n",
        "        \r\n",
        "    def ingest_schoolinfo(self):\r\n",
        "        oea.ingest(f'xporter/SchoolInfo', 'SchoolID')\r\n",
        "        oea.refine('xporter/SchoolInfo', self.schemas['schoolinfo'], 'SchoolID')\r\n",
        "\r\n",
        "\r\n",
        "    def ingest_schoolinfo_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.schoolinfo\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.schoolinfo_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/schoolinfo_ingested',save_format = \"parquet\", primary_key='SchoolID')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/schoolinfo_refined',save_format = \"parquet\", primary_key='SchoolID')\r\n",
        "        \r\n",
        "    \r\n",
        "    def _prepare_students(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        #oea.rm_if_exists(oea.stage1np + '/xporter/schoolinfocsv')\r\n",
        "        df_studinfo = None\r\n",
        "        # loop through school EstabId folders landed by Xporter and union schoolinfo\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            if folder.isnumeric():\r\n",
        "                print(folder)\r\n",
        "                try:\r\n",
        "                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/Students*'\r\n",
        "                    df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    dfc = df.select(F.explode('Students').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    dfc = dfc.drop('AddressBlock')\r\n",
        "                    dfc = dfc.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
        "                    dfc = dfc.withColumn('SchoolID',lit(folder))\r\n",
        "                    newdf = dfc.withColumn(\"UniqueStudentId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))\r\n",
        "                    newdf.show()\r\n",
        "                    if df_studinfo is None:\r\n",
        "                        df_studinfo = newdf\r\n",
        "                    else:\r\n",
        "                        df_studinfo = df_studinfo.union(newdf)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "        \r\n",
        "        print('df_studinfo')\r\n",
        "        df_studinfo.show()\r\n",
        "        df_studinfo = df_studinfo.filter(col(\"UPN\") != \"undefined\")\r\n",
        "        df_studinfo = df_studinfo.filter(~isnull(col(\"UPN\")))\r\n",
        "        df_studinfo = df_studinfo.filter((length(trim(col(\"UPN\"))) > 9))\r\n",
        "        csvString = df_studinfo.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/Students', 'Students.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/Students')\r\n",
        "        display(df)\r\n",
        "    \r\n",
        "\r\n",
        "    def ingest_students(self):\r\n",
        "        oea.ingest(f'xporter/Students', 'UniqueStudentId')\r\n",
        "        oea.refine('xporter/Students', self.schemas['students'], 'UniqueStudentId')\r\n",
        "    \r\n",
        "    \r\n",
        "    def ingest_students_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.students\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.students_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/students_ingested',save_format = \"parquet\", primary_key='UniqueStudentId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/students_refined',save_format = \"parquet\", primary_key='UniqueStudentId')\r\n",
        "\r\n",
        "\r\n",
        "    def _prepare_attendancesummary(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        df_attendancesummary = None\r\n",
        "        for folder in oea.get_folders(xporter.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            if folder.isnumeric():\r\n",
        "                print(folder)\r\n",
        "                try:\r\n",
        "                    xporterPath = xporter.get_oea_path()+'/Transactional/xporter/'+folder+'/AttendanceSummary*'\r\n",
        "                    new_df = xporter.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    new_df = new_df.select(F.explode('AttendanceSummary').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    new_df = new_df.drop('AddressBlock')\r\n",
        "                    new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
        "                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
        "                    new_df = new_df.withColumn(\"UniqueAttendanceId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
        "                    if df_attendancesummary is None:\r\n",
        "                        df_attendancesummary = new_df\r\n",
        "                    else:\r\n",
        "                        df_attendancesummary = df_attendancesummary.union(new_df)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "\r\n",
        "        print(df_attendancesummary)\r\n",
        "        df_attendancesummary.show()   \r\n",
        "        csvString = df_attendancesummary.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/AttendanceSummary', 'attendancesummary.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/AttendanceSummary')\r\n",
        "        display(df)\r\n",
        "\r\n",
        "    def ingest_attendancesummary(self):\r\n",
        "        oea.ingest(f'xporter/AttendanceSummary', 'UniqueAttendanceId')\r\n",
        "        oea.refine('xporter/AttendanceSummary', self.schemas['attendancesummary'], 'UniqueAttendanceId')\r\n",
        "    \r\n",
        "    def ingest_attendancesummary_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.attendancesummary\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.attendancesummary_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/attendancesummary_ingested',save_format = \"parquet\", primary_key='UniqueAttendanceId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/attendancesummary_refined',save_format = \"parquet\", primary_key='UniqueAttendanceId')\r\n",
        "\r\n",
        "    \r\n",
        "    def _prepare_groups(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        df_groups1 = None\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            print(folder)\r\n",
        "            if folder.isnumeric():\r\n",
        "                try:\r\n",
        "                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/groups*'\r\n",
        "                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    new_df = new_df.select(F.explode('Group').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
        "                    new_df = new_df.withColumn(\"UniqueGroupId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
        "                    if df_groups1 is None:\r\n",
        "                        df_groups1 = new_df\r\n",
        "                    else:\r\n",
        "                        df_groups1 = df_groups1.union(new_df)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "\r\n",
        "        csvString = df_groups1.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/Groups', 'Groups.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/Groups')\r\n",
        "        display(df)\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "    def ingest_groups(self):\r\n",
        "        oea.ingest(f'xporter/Groups', 'UniqueGroupId')\r\n",
        "        oea.refine('xporter/Groups', self.schemas['groups'], 'UniqueGroupId')\r\n",
        "    \r\n",
        "    def ingest_groups_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.groups\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.groups_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/groups_ingested',save_format = \"parquet\", primary_key='UniqueGroupId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/groups_refined',save_format = \"parquet\", primary_key='UniqueGroupId')\r\n",
        "\r\n",
        "    \r\n",
        "    def _prepare_HistoricalAttendanceSummary(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        df_histattendancSummary = None\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            if folder.isnumeric():\r\n",
        "                print(folder)\r\n",
        "            try:\r\n",
        "                xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/HistoricalAttendanceSummary*'\r\n",
        "                new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                new_df = new_df.select(F.explode('HistoricalAttendanceSummary').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                new_df = new_df.drop('AddressBlock')\r\n",
        "                new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
        "                new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
        "                new_df = new_df.withColumn(\"UniqueHistoricalAttendanceId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"Id\")))           \r\n",
        "                if df_histattendancSummary is None:\r\n",
        "                    df_histattendancSummary = new_df\r\n",
        "                else:\r\n",
        "                    df_histattendancSummary = df_histattendancSummary.union(new_df)\r\n",
        "            except:\r\n",
        "                pass\r\n",
        "\r\n",
        "        csvString = df_histattendancSummary.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/HistoricalAttendanceSummary', 'HistoricalAttendanceSummary.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/Students')\r\n",
        "        display(df)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def ingest_HistoricalAttendanceSummary(self):\r\n",
        "        oea.ingest(f'xporter/HistoricalAttendanceSummary', 'UniqueHistoricalAttendanceId')\r\n",
        "        oea.refine('xporter/HistoricalAttendanceSummary', self.schemas['HistoricalAttendanceSummary'], 'UniqueHistoricalAttendanceId')#ingesting into stage 2\"\"\"#ingesting into stage 2\"\"\"\r\n",
        "    \r\n",
        "    \r\n",
        "    def ingest_HistoricalAttendanceSummary_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.historicalattendancesummary\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.historicalattendancesummary_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/historicalattendancesummary_ingested',save_format = \"parquet\", primary_key='UniqueHistoricalAttendanceId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/historicalattendancesummary_refined',save_format = \"parquet\", primary_key='UniqueHistoricalAttendanceId')\r\n",
        "   \r\n",
        "\r\n",
        "    def _prepare_staff(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        df_staff = None\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            print(folder)\r\n",
        "            if folder.isnumeric():\r\n",
        "                try:\r\n",
        "                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/staff*'\r\n",
        "                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    new_df = new_df.select(F.explode('staff').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
        "                    new_df = new_df.drop('AddressBlock')\r\n",
        "                    new_df = new_df.withColumn(\"AddressBlock\",lit(\"undefined\"))\r\n",
        "                    new_df = new_df.withColumn(\"UniqueStaffId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"IdaasId\")))           \r\n",
        "                    if df_staff is None:\r\n",
        "                        df_staff = new_df\r\n",
        "                    else:\r\n",
        "                        df_staff = df_staff.union(new_df)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "\r\n",
        "        csvString = df_staff.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/Staff', 'Staff.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/Staff')\r\n",
        "        display(df)\r\n",
        "\r\n",
        "    \r\n",
        "    def ingest_staff(self):\r\n",
        "        oea.ingest(f'xporter/Staff', 'UniqueStaffId')\r\n",
        "        oea.refine('xporter/Staff', self.schemas['staff'], 'UniqueStaffId')\r\n",
        "    \r\n",
        "    \r\n",
        "    def ingest_staff_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.staff\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.staff_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/staff_ingested',save_format = \"parquet\", primary_key='UniqueStaffId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/staff_refined',save_format = \"parquet\", primary_key='UniqueStaffId')\r\n",
        "    \r\n",
        "    def _prepare_StudentMembers(self):\r\n",
        "        from pyspark.sql.functions import lit, concat, col, isnull, trim, length\r\n",
        "        df_studentmembers = None\r\n",
        "        for folder in oea.get_folders(self.get_oea_path() + '/Transactional/xporter'):\r\n",
        "            print(folder)\r\n",
        "            if folder.isnumeric():\r\n",
        "                try:\r\n",
        "                    xporterPath = self.get_oea_path()+'/Transactional/xporter/'+folder+'/groups*'\r\n",
        "                    new_df = self.json_from_xporter(xporterPath, multiline = True)\r\n",
        "                    new_df = new_df.select(F.explode('StudentMembers').alias('exploded_values')).select(\"exploded_values.*\")\r\n",
        "                    new_df = new_df.withColumn('SchoolID',lit(folder)) \r\n",
        "                    new_df = new_df.withColumn(\"UniqueStudentId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"StudentIdaasId\")))\r\n",
        "                    new_df = new_df.withColumn(\"UniqueGroupId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"GroupIdaasId\")))\r\n",
        "                    new_df = new_df.withColumn(\"UniqueStudentMemberId\", concat(col(\"SchoolID\"), lit(\"_\"), col(\"Id\")))           \r\n",
        "                    if df_studentmembers is None:\r\n",
        "                        df_studentmembers = new_df\r\n",
        "                    else:\r\n",
        "                        df_studentmembers = df_studentmembers.union(new_df)\r\n",
        "                except:\r\n",
        "                    pass\r\n",
        "\r\n",
        "        csvString = df_studentmembers.toPandas().to_csv(index=False)\r\n",
        "        oea.land(csvString, 'xporter/StudentMembers', 'StudentMembers.csv', oea.DELTA_BATCH_DATA)\r\n",
        "        df = oea.load_csv(f'stage1/Transactional/xporter/StudentMembers')\r\n",
        "        display(df)\r\n",
        "\r\n",
        "    \r\n",
        "    def ingest_StudentMembers(self):\r\n",
        "        oea.ingest(f'xporter/StudentMembers', 'UniqueStudentMemberId')\r\n",
        "        oea.refine('xporter/StudentMembers', self.schemas['StudentMembers'], 'UniqueStudentMemberId')\r\n",
        "\r\n",
        "    \r\n",
        "    def ingest_StudentMembers_stage3(self, ingestDatabaseName, refineDatabaseName):\r\n",
        "        \"\"\" Processes delta batch data from stage2 into stage3 \"\"\"\r\n",
        "        df_ingested = spark.sql(f\"select * from {ingestDatabaseName}.studentmembers\")\r\n",
        "        display(df_ingested)\r\n",
        "        df_ingested.printSchema()\r\n",
        "        df_refined = spark.sql(f\"select * from {refineDatabaseName}.studentmembers_lookup\")\r\n",
        "        display(df_refined)\r\n",
        "        #writing files in parquet format\r\n",
        "        xporter.overwrite_to_path(df_ingested,f'stage3/xporter/studentmembers_ingested',save_format = \"parquet\", primary_key='UniqueStudentMemberId')\r\n",
        "        xporter.overwrite_to_path(df_refined,f'stage3/xporter/studentmembers_refined',save_format = \"parquet\", primary_key='UniqueStudentMemberId')\r\n",
        "        \r\n",
        "xporter = Xporter()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}