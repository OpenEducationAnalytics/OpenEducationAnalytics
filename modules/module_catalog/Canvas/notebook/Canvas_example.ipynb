{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test for processing Canvas data\r\n",
        "\r\n",
        "This notebook demonstrates possible data processing and exploration of the Canvas data, using the OEA_py class notebook. \r\n",
        "\r\n",
        "Most of the data processing done in this notebook are also achieved by executing the Canvas module main pipeline. This notebook is designed as an alternate approach to the same processing, as well as module data exploration and visualization. \r\n",
        "\r\n",
        "The steps are clearly outlined below:\r\n",
        "1. Set the workspace,\r\n",
        "2. Land Canvas Module Higher Ed. Test Data,\r\n",
        "3. Pre-Process Canvas Module Test Data,\r\n",
        "4. Ingest the Canvas Module Test Data,\r\n",
        "5. Refine the Canvas Module Test Data, \r\n",
        "6. Demonstrate Lake Database Queries/Final Remarks, and\r\n",
        "7. Appendix"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run OEA_py"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) set the workspace (this determines where in the data lake you'll be writing to and reading from).\r\n",
        "# You can work in 'dev', 'prod', or a sandbox with any name you choose.\r\n",
        "# For example, Sam the developer can create a 'sam' workspace and expect to find his datasets in the data lake under oea/sandboxes/sam\r\n",
        "oea.set_workspace('dev')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.) Land Canvas Module Higher Ed. Test Data\r\n",
        "\r\n",
        "Directory: ```GitHub.com (raw data) -> stage1/Transactional/canvas_raw```\r\n",
        "\r\n",
        "The code block below lands 13 OEA Canvas module test data tables, formatted as Canvas Higher Ed. data in your data lake. \r\n",
        "\r\n",
        "Canvas test data JSON tables landed in stage 1:\r\n",
        " 1. **accounts**\r\n",
        " 2. **assignments**\r\n",
        " 3. **content_tags**\r\n",
        " 4. **context_modules**\r\n",
        " 5. **courses**\r\n",
        " 6. **course_sections**\r\n",
        " 7. **enrollments**\r\n",
        " 8. **enrollment_terms**\r\n",
        " 9. **quiz_submissions**\r\n",
        " 10. **quizzes**\r\n",
        " 11. **roles**\r\n",
        " 12. **submissions**\r\n",
        " 13. **users** \r\n",
        "\r\n",
        "**To-Do's:**\r\n",
        " - Correct the test dataset as needed"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1) Land batch data files into stage1 of the data lake.\r\n",
        "# In this example we pull Canvas HEd test json data files from github and land it in oea/dev/stage1/Transactional/canvas/v2.0\r\n",
        "import datetime\r\n",
        "currentDate = datetime.datetime.now()\r\n",
        "currentDateTime = currentDate.strftime(\"%Y-%m-%d %H-%M-%S\")\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/accounts.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/accounts', 'accounts_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/courses.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/courses', 'courses_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/course_sections.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/course_sections', 'coursesections_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/roles.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/roles', 'roles_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/users.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/users', 'users_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "# normally, these three tables should be landed as delta_batch_data but since functionality is limited for processing delta data, we assume they're snapshot for now.\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/enrollments.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/enrollments', 'enrollments_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/enrollment_terms.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/enrollment_terms', 'enrollmentterms_hed_test_data.csv', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/content_tags.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/content_tags', 'contenttags_hed_test_data.json', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/context_modules.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/context_modules', 'contextmodules_hed_test_data.json', oea.SNAPSHOT_BATCH_DATA, currentDateTime)\r\n",
        "\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/assignments.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/assignments', 'assignments_hed_test_data.csv', oea.ADDITIVE_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/quizzes.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/quizzes', 'quizzes_hed_test_data.csv', oea.ADDITIVE_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/quiz_submissions.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/quiz_submissions', 'quizsubmissions_hed_test_data.csv', oea.ADDITIVE_BATCH_DATA, currentDateTime)\r\n",
        "data = requests.get('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/hed_test_data/submissions.json').text\r\n",
        "oea.land(data, 'canvas_raw/v2.0/submissions', 'submissions_hed_test_data.csv', oea.ADDITIVE_BATCH_DATA, currentDateTime)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.) Pre-Process Canvas Module Test Data\r\n",
        "\r\n",
        "Directory: ```stage1/Transactional/canvas_raw -> stage1/Transactional/canvas```\r\n",
        "\r\n",
        "This step is responsible for pre-processing the Canvas module test data from stage1 back to stage1.\r\n",
        "\r\n",
        "The code blocks in this step read in the original JSON tables using the ```pd.read_json(..., lines=True)``` function, performs any ad hoc data conversions, and writes the table to stage1 as a CSV.\r\n",
        "\r\n",
        "**To-Do's:**\r\n",
        " - Check if this if test data matches production data, with raw JSONs oriented as records (one JSON row represents a row in the df)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) this step pre-processing the canvas data through reading in the JSONs as records, corrects any schema discepancies and then writes out the df as a CSV in stage1.\r\n",
        "# there is no data transformation happening in this step besides properly reading in the column dtypes properly.\r\n",
        "def preprocess_canvas_dataset(tables_source):\r\n",
        "    items = oea.get_folders(tables_source)\r\n",
        "    for item in items: \r\n",
        "        if item == '_preprocessed_tables':\r\n",
        "            logger.info('Ignoring existing _preprocessed_tables folder.')\r\n",
        "        else:\r\n",
        "            table_path = tables_source +'/'+ item\r\n",
        "            # find the batch data type of the table\r\n",
        "            batch_type_folder = oea.get_folders(table_path)\r\n",
        "            batch_type = batch_type_folder[0]\r\n",
        "            # grab only the latest folder in stage1, used to write the JSON -> CSV to the same rundate folder timestamp\r\n",
        "            # idea is to mimic the same directory structure of tables landed in stage1\r\n",
        "            latest_dt = oea.get_latest_runtime(f'{table_path}/{batch_type}', \"rundate=%Y-%m-%d %H-%M-%S\")\r\n",
        "            latest_dt = latest_dt.strftime(\"%Y-%m-%d %H-%M-%S\")\r\n",
        "            pdf = pd.read_json(oea.to_url(f'{table_path}/{batch_type}/rundate={latest_dt}/*.json'),lines=True)\r\n",
        "            if item == 'submissions':\r\n",
        "                pdf[['graded_anonymously', 'excused']] = pdf[['graded_anonymously', 'excused']].astype(str) # NOTE: df doesn't load properly if array columns aren't cast to strings\r\n",
        "            df = spark.createDataFrame(pdf)\r\n",
        "            # ad hoc step(s) \r\n",
        "            if item == 'accounts':\r\n",
        "                df = df.withColumn('parent_account_id', df['parent_account_id'].cast(LongType()))\r\n",
        "            elif item == 'assignments':\r\n",
        "                df = df.withColumn('submission_types', df['submission_types'].cast(StringType()))\r\n",
        "            elif item == 'quiz_submissions':\r\n",
        "                df = df.withColumn('score', F.round(df['score'], 2)).withColumn('kept_score', F.round(df['kept_score'], 2)).withColumn('score_before_regrade', F.round(df['score_before_regrade'], 2))\r\n",
        "            elif item == 'submissions':\r\n",
        "                df = df.withColumn('quiz_submission_id', df['quiz_submission_id'].cast(LongType())).withColumn('score', F.round(df['score'], 2)).withColumn('published_score', F.round(df['published_score'], 2))\r\n",
        "            else:\r\n",
        "                logger.info(f'no ad hoc processing needed for the Canvas {item} table.')\r\n",
        "            # create the new location for the converted CSVs, and write back to stage1\r\n",
        "            new_table_path = f'stage1/Transactional/canvas/v{version}/{item}/{batch_type}/rundate={latest_dt}'\r\n",
        "            df.coalesce(1).write.save(oea.to_url(f'{new_table_path}'), format='csv', mode='overwrite', header='true', mergeSchema='true')\r\n",
        "            # remove the _SUCCESS file\r\n",
        "            oea.rm_if_exists(new_table_path + '/_SUCCESS', False)\r\n",
        "            logger.info('Pre-processed table: ' + item + ' from: ' + table_path)\r\n",
        "    logger.info('Finished pre-processing Canvas tables')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the version number and pre-process the dataset\r\n",
        "version = '2.0'\r\n",
        "preprocess_canvas_dataset(f'stage1/Transactional/canvas_raw/v{version}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.) Ingest the Canvas Module Test Data\r\n",
        "\r\n",
        "Directory: ```stage1/Transactional/canvas -> stage2/Ingested/canvas```\r\n",
        "\r\n",
        "This step ingests the Canvas module test data from stage1 to stage2/Ingested.\r\n",
        "\r\n",
        "The code blocks in this step ingest the data using a the ```oea.ingest()``` function as normally."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function ingests each canvas table from stage1/../canvas_preprocessed/...\r\n",
        "def ingest_canvas_dataset(tables_source):\r\n",
        "    items = oea.get_folders(f'stage1/Transactional/{tables_source}')\r\n",
        "    for item in items: \r\n",
        "        table_path = f'canvas/v{version}/{item}'\r\n",
        "        try:\r\n",
        "            # 3 paths: check_path is for checking whether the table should be ingested, read_path is for reading the stage1 CSV location, write path for stage2 ingested location\r\n",
        "            if item == 'metadata.csv':\r\n",
        "                logger.info('ignore metadata csv - not a table to be ingested')\r\n",
        "            elif item == 'content_tags':\r\n",
        "                oea.ingest(table_path, 'content_id')\r\n",
        "            else:\r\n",
        "                oea.ingest(table_path, 'id')\r\n",
        "        except AnalysisException as e:\r\n",
        "            # This means the table may have not been properly refined due to errors with the primary key not aligning with columns expected in the lookup table.\r\n",
        "            pass\r\n",
        "    logger.info('Finished ingesting the most recent Canvas data')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ingest the canvas dataset\r\n",
        "version = '2.0'\r\n",
        "ingest_canvas_dataset(f'canvas/v{version}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5) Now you can run queries against the auto-generated \"lake database\" with the ingested Canvas data.\r\n",
        "df = spark.sql(\"select * from ldb_dev_s2i_canvas_v2p0.course_sections\")\r\n",
        "display(df.limit(10))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.) Refine the Canvas Module Test Data\r\n",
        "\r\n",
        "Directory: ```stage2/Ingested/canvas -> stage2/Refined/canvas```\r\n",
        "\r\n",
        "This step then refines the Canvas test data from stage2/Ingested to stage2/Refined, using the metadata.csv. This step is responsible for pseudonymization, which preserves sensitive student information by either hashing or masking the sensitive columns. \r\n",
        "\r\n",
        "Tables are separated into either ```stage2/Refined/canvas/v2.0/general``` or ```stage2/Refined/canvas/v2.0/sensitive```, depending on whether each table is pseudonymized or has a sensitive column-hashing/masking mapping, respectively.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_canvas(entity_path, metadata=None, primary_key='id'):\r\n",
        "    source_path = f'stage2/Ingested/{entity_path}'\r\n",
        "    primary_key = oea.fix_column_name(primary_key) # fix the column name, in case it has a space in it or some other invalid character\r\n",
        "    path_dict = oea.parse_path(source_path)\r\n",
        "    sink_general_path = path_dict['entity_parent_path'].replace('Ingested', 'Refined') + '/general/' + path_dict['entity']\r\n",
        "    sink_sensitive_path = path_dict['entity_parent_path'].replace('Ingested', 'Refined') + '/sensitive/' + path_dict['entity'] + '_lookup'\r\n",
        "    if not metadata:\r\n",
        "        all_metadata = oea.get_metadata_from_path(path_dict['entity_parent_path'])\r\n",
        "        metadata = all_metadata[path_dict['entity']]\r\n",
        "\r\n",
        "    df_changes = oea.get_latest_changes(source_path, sink_general_path)\r\n",
        "    spark_schema = oea.to_spark_schema(metadata)\r\n",
        "    df_changes = oea.modify_schema(df_changes, spark_schema)        \r\n",
        "\r\n",
        "    if df_changes.count() > 0:\r\n",
        "        df_pseudo, df_lookup = oea.pseudonymize(df_changes, metadata)\r\n",
        "        oea.upsert(df_pseudo, sink_general_path, primary_key) # todo: remove this assumption that the primary key will always be hashed during pseduonymization\r\n",
        "        oea.upsert(df_lookup, sink_sensitive_path, primary_key)    \r\n",
        "        oea.add_to_lake_db(sink_general_path)\r\n",
        "        oea.add_to_lake_db(sink_sensitive_path)\r\n",
        "        logger.info(f'Processed {df_changes.count()} updated rows from {source_path} into stage2/Refined')\r\n",
        "    else:\r\n",
        "        logger.info(f'No updated rows in {source_path} to process.')\r\n",
        "    return df_changes.count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) this step refines the data through the use of metadata (this is where the pseudonymization of the data occurs).\r\n",
        "def refine_canvas_dataset(tables_source):\r\n",
        "    items = oea.get_folders(tables_source)\r\n",
        "    for item in items: \r\n",
        "        table_path = tables_source +'/'+ item\r\n",
        "        if item == 'metadata.csv':\r\n",
        "            logger.info('ignore metadata processing, since this is not a table to be ingested')\r\n",
        "        else:\r\n",
        "            try:\r\n",
        "                if item == 'accounts':\r\n",
        "                    refine_canvas('canvas/v2.0/accounts', metadata[item], 'id_pseudonym')\r\n",
        "                if item == 'content_tags':\r\n",
        "                    refine_canvas('canvas/v2.0/content_tags', metadata[item], 'content_id')\r\n",
        "                elif item == 'users':\r\n",
        "                    refine_canvas('canvas/v2.0/users', metadata[item], 'id_pseudonym')\r\n",
        "                else:\r\n",
        "                    refine_canvas('canvas/v2.0/' + item, metadata[item], 'id')\r\n",
        "            except AnalysisException as e:\r\n",
        "                # This means the table may have not been properly refined due to errors with the primary key not aligning with columns expected in the lookup table.\r\n",
        "                pass\r\n",
        "            \r\n",
        "            logger.info('Refined table: ' + item + ' from: ' + table_path)\r\n",
        "    logger.info('Finished refining Canvas tables')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = oea.get_metadata_from_url('https://raw.githubusercontent.com/microsoft/OpenEduAnalytics/main/modules/module_catalog/Canvas/test_data/metadata_v2.csv')\r\n",
        "refine_canvas_dataset('stage2/Ingested/canvas/v2.0')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.) Demonstrate Lake Database Queries/Final Remarks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# non-hashed primary keys are not automatically added to the lake db - add these tables\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/assignments')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/content_tags')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/context_modules')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/courses')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/course_sections')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/enrollments')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/enrollment_terms')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/quizzes')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/quiz_submissions')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/roles')\r\n",
        "oea.add_to_lake_db('stage2/Refined/canvas/v2.0/general/submissions')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Now you can query the refined data tables in the lake db\r\n",
        "df = spark.sql(\"select * from ldb_dev_s2r_canvas_v2p0.enrollments\")\r\n",
        "display(df)\r\n",
        "df.printSchema()\r\n",
        "df = spark.sql(\"select * from ldb_dev_s2r_canvas_v2p0.users\")\r\n",
        "display(df)\r\n",
        "df.printSchema()\r\n",
        "# You can use the \"lookup\" table for joins (people with restricted access won't be able to perform this query because they won't have access to data in the \"sensitive\" folder in the data lake)\r\n",
        "df = spark.sql(\"select e.course_section_id, e.type, e.workflow_state, u.id_pseudonym, u.name \\\r\n",
        "                from ldb_dev_s2r_canvas_v2p0.enrollments e, ldb_dev_s2r_canvas_v2p0.users u where e.user_id_pseudonym = u.id_pseudonym\")\r\n",
        "display(df.limit(10))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to reset this example (deleting all the example Canvas data in your workspace)\r\n",
        "oea.rm_if_exists('stage1/Transactional/canvas_raw')\r\n",
        "oea.rm_if_exists('stage1/Transactional/canvas')\r\n",
        "oea.rm_if_exists('stage2/Ingested/canvas')\r\n",
        "oea.rm_if_exists('stage2/Refined/canvas')\r\n",
        "oea.drop_lake_db('ldb_dev_s2i_canvas_v2p0')\r\n",
        "oea.drop_lake_db('ldb_dev_s2r_canvas_v2p0')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate an initial metadata file for manual modification\r\n",
        "metadata = oea.create_metadata_from_lake_db('ldb_dev_s2i_canvas_v2p0')\r\n",
        "dlw = DataLakeWriter(oea.to_url('stage1/Transactional/canvas'))\r\n",
        "dlw.write('metadata.csv', metadata)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sql db for the ingested Canvas data\r\n",
        "oea.create_sql_db('stage2/Ingested/canvas')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oea.create_sql_db('stage2/Refined/canvas')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}