{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML modeling\n",
        "\n",
        "Prior featurization in the data engineering pipeline creates a main dataset with a unique on student id (registered AML). This notebook is intended to be run on AML and train ML model(s) for PowerBI and RAI dashboard consumption.   \n",
        "\n",
        "### Steps \n",
        "\n",
        "1. **Preprocessing data features and labels** \n",
        "- basic preprocessing including missing values and categorical variables\n",
        "- label definition: valid values in Vulnerability column as nominated students (class 1) and missing values as not nominated (class 0) \n",
        "- Create proxy labels based on medical features based on expert opinion\n",
        "\n",
        "2. **Training and evaluating models**\n",
        "\n",
        "- use 80-20 train-test split on the entire data set\n",
        "- compute k-fold cross-validation performance with undersampling technique applied on training set \n",
        "- build a set of supervised learning models for benchmarking\n",
        "- additional diagnostics (e.g. compare resampling strategies for imbalanced label, and fairness mitigation) \n",
        " \n",
        "3. **Register model and data on AML for dashboard consumption**\n",
        "- user specifies a model name to examine on dashboards\n",
        "- for PowerBI dashboard, all of the predicted data of a model will be registered; and\n",
        "- for RAI dashboard, a sklearn model and a sample (up to 5000 rows) of the predicted data will be registered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1677083088519
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# make sure you run this notebook on azureml_py38 conda environment (aka Python 3.8 - AzureML - one of the default conda environments on AML compute instances)\n",
        "# uncomment this line and install these dependencies if you are running this notebook for the first time\n",
        "#!pip install protobuf==3.20.1 scikit-learn==1.2.0 imbalanced-learn==0.9.1 fairlearn==0.8.0 fasttreeshap shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677083107468
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "import time\n",
        "import toml\n",
        "from functools import partial\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_colwidth\", 128)\n",
        "pd.set_option(\"display.max_rows\", 500)\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import loguniform, uniform\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "from IPython.display import display\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RepeatedStratifiedKFold, ParameterSampler\n",
        "from sklearn.linear_model import LogisticRegression as skLogit, LogisticRegressionCV as skLogitCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import *\n",
        "import imblearn\n",
        "from imblearn.pipeline import Pipeline as pipeline_with_sampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import interpret\n",
        "from interpret.glassbox import ExplainableBoostingClassifier\n",
        "import fasttreeshap\n",
        "import shap\n",
        "import fairlearn\n",
        "from fairlearn.metrics import (\n",
        "    MetricFrame, plot_model_comparison,\n",
        "    selection_rate, mean_prediction, demographic_parity_difference, demographic_parity_ratio,\n",
        "    false_positive_rate, false_negative_rate, true_positive_rate, true_negative_rate,\n",
        "    false_positive_rate_difference, false_negative_rate_difference, equalized_odds_ratio,\n",
        "    equalized_odds_difference, count)\n",
        "from fairlearn.reductions import GridSearch, DemographicParity, ErrorRate\n",
        "\n",
        "import mlflow\n",
        "from azureml.core import Workspace, Datastore, Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1677083107627
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.41.0\n",
            "0.8.0\n",
            "0.2.7\n",
            "1.2.0\n",
            "0.9.1\n",
            "1.1.5\n",
            "1.21.6\n"
          ]
        }
      ],
      "source": [
        "for pkg in [shap, fairlearn, interpret, sklearn, imblearn, pd, np]:\n",
        "    print(pkg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "Load the main dataset registered on AML by Synapse pipeline (output of data engineering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1677083117816
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "workspace = Workspace.from_config()\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name=\"dataset-MainData\")\n",
        "df = dataset.to_pandas_dataframe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Preprocess dataset for training ML models\n",
        "\n",
        "\n",
        "### Basic feature preprocessing including missing values and categorical variables\n",
        "- validate feature columns (there will be mix of categorical and numeric features)\n",
        "- categorize features for ease of understanding\n",
        "- drop year 12 students since we are uncertain why they have no labels (hence the model should not be used to predict on these students)\n",
        "- drop avg_presentStreak and avg_absentStreak which correlates more than 90% with their min or max versions (average estimates are sensitive to outliers).  \n",
        "- deduplicate data by student id\n",
        "- convert features that should be int but casted as strings or floats\n",
        "- fill missing values from medical features\n",
        "- check if there is no missing value in features\n",
        "\n",
        "\n",
        "### Label definition\n",
        "- valid values in Vulnerability column as nominated students (class 1) and missing values as not nominated (class 0) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1677083117977
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# constants already in dataframe\n",
        "STUDENT_ID = \"StudentDwRefId_pseudonym\"\n",
        "BINARY_TARGET = \"Vulnerability\"\n",
        "MULTICLASS_TARGET = \"LevelofNeed\"\n",
        "SCHOOL_ID =  \"StudentSchoolEnrolmentDwRefId_pseudonym\" # provided school info table is used\n",
        "TIME_STAMP = \"TimeStamp\"\n",
        "\n",
        "# new constants \n",
        "NOMINATION_TARGET = \"Nomination\"\n",
        "PROXY_TARGET = f\"Proxy{BINARY_TARGET}\"\n",
        "PROXY_NOMINATION_TARGET = f\"Proxy{NOMINATION_TARGET}\"\n",
        "SENSITIVE_COLUMNS = [\"EconomicDisadvantageSTAS\", \"Disability\"]\n",
        "\n",
        "# model parameters\n",
        "SEED = 1\n",
        "DEFAULT_RNG = np.random.default_rng(SEED) # set seed for random generator\n",
        "F_SCORE_BETA = 10  # recall is considered F_SCORE_BETA times as important as precision; see documentation on F-beta scores for details  \n",
        "SHOW = False # show diagnostic plots globally \n",
        "UNDERSAMPLE_RATIO = \"auto\"  # if None, turn off undersampling; otherwise, set value for sampling_strategy parameter in imblearn\n",
        "OVERSAMPLE_RATIO = None # if None, turn off oversampling; otherwise, set value for sampling_strategy parameter in imblearn\n",
        "N_RF_SAMPLES_TO_EXPLAIN = 1000  # explaining sklearn random forest is slow; limit datapoints to explain to < 1000 when debugging; Set to None to override \n",
        "SEARCH_HP = False # if True, turn on hyperparameter search; update hp_grid parameter in the train_cv function definition if needed\n",
        "\n",
        "# categorize features\n",
        "MEDICAL_CONDITION_COLS = df.columns[df.columns.str.contains(\"cond$\", regex=True)].tolist()\n",
        "MEDICAL_ALERT_COLS = df.columns[df.columns.str.contains(\"alert$\", regex=True)].tolist()\n",
        "DISCIPLINARY_COLS = df.columns[df.columns.str.contains(\"^DisciplinarySanction\", regex=True)].tolist()\n",
        "PROTECTION_COLS = df.columns[df.columns.str.contains(\"^ProtectionOrderCount\", regex=True)].tolist()\n",
        "ATTENDANCE_COLS = [\"sum_absentStreak\"]\n",
        "\n",
        "# the version with the \"_earliest_\" is redundant  \n",
        "STUDENT_TEST_SCORE_COLS = [\n",
        "    \"ActualScore_latest_ACFEN\",\n",
        "    \"CalendarYear_latest_ACFEN\",\n",
        "    \"YearLevelCode_latest_ACFEN\",\n",
        "    \"ActualScore_latest_ACFMT\",\n",
        "    \"CalendarYear_latest_ACFMT\",\n",
        "    \"YearLevelCode_latest_ACFMT\",\n",
        "    \"ActualScore_KDC\",\n",
        "    \"CalendarYear_KDC\"\n",
        "]\n",
        "\n",
        "DEMOGRAPHIC_COLS = [\n",
        "    \"Gender\", \n",
        "    \"EconomicDisadvantageSTAS\", \n",
        "    \"Disability\", \n",
        "    \"IndigenousStatusInd\",\n",
        "    \"IndependentStatusInd\",\n",
        "    \"StudentATSIStatusAny_date2019\", \n",
        "    \"StudentInStateCareIndAny_date2019\", \n",
        "    \"ParentsHighestEducationLevel\", \n",
        "    \"ParentsHighestOccupationLevel\",\n",
        "    \"BirthMonth\", \n",
        "    \"BirthYear\", \n",
        "    \"CountryOfBirth\", \n",
        "    \"PermanentResident\",\n",
        "    \"InternationalStudentType\", \n",
        "    \"LaunchingIntoLearningInd\", \n",
        "    \"StudentHasActiveEduPointEnrolment\", \n",
        "    \"StudentHasActiveTasTafeEnrolment\", \n",
        "    \"StudentTransitionPlanStatusYear10\"\n",
        "]\n",
        "\n",
        "ACTION_COLS = [\n",
        "    \"Action_cnt_2019\", \"wasExpulsed_date2019\", \n",
        "    \"suspensionExtensionCount_date2019\", \"suspensionExtensionTotalDays_date2019\", \"suspensionCount_date2019\", \n",
        "    \"suspensionTotalDays_date2019\", \"exclusionCount_date2019\", \"exclusionTotalDays_date2019\"]\n",
        "\n",
        "OTHER_MEDICAL_COLS = [\"Autism\", \"ECIS\", \"HearingImpaired\", \"IQ55_70\", \"Intellectual\", \"KinderSupport\", \"Level1\", \"Level2\", \"Medical\", \"Multiple\", \"Physical\", \"Psychiatric\", \"VisionImpaired\"]\n",
        "\n",
        "# categorize features for ease of interpretation and visualization\n",
        "FEATURE_MAP = {\n",
        "    \"Medical\": MEDICAL_CONDITION_COLS + MEDICAL_ALERT_COLS + OTHER_MEDICAL_COLS,\n",
        "    \"Demographic\": DEMOGRAPHIC_COLS + PROTECTION_COLS, \n",
        "    \"Action\": ACTION_COLS + DISCIPLINARY_COLS,\n",
        "    \"Test\": STUDENT_TEST_SCORE_COLS,\n",
        "    \"Attendance\": ATTENDANCE_COLS\n",
        "}\n",
        "\n",
        "MEDICAL_SERIOUSNESS = {\"MINOR\": 1, \"MODERATE\": 2, \"SERIOUS\": 3, \"FATAL\":4} \n",
        "# other values will be fill with 0\n",
        "NA_CONDITION_VALUE = 0 \n",
        "\n",
        "MEDICAL_ALERTIND = {\"Y\": 1, \"N\":0} \n",
        "# other values will be fill with -1\n",
        "NA_ALERT_VALUE = -1\n",
        "\n",
        "INT_ENCODE_COLS = MEDICAL_CONDITION_COLS + MEDICAL_ALERT_COLS\n",
        "\n",
        "ONE_HOT_ENCODE_COLS = [\n",
        "    \"Gender\",\n",
        "    \"Disability\",\n",
        "    \"LaunchingIntoLearningInd\",\n",
        "    \"IndigenousStatusInd\",\n",
        "    \"StudentTransitionPlanStatusYear10\",\n",
        "    \"StudentHasActiveTasTafeEnrolment\",\n",
        "    \"StudentHasActiveEduPointEnrolment\",\n",
        "    \"PermanentResident\",\n",
        "    \"InternationalStudentType\",\n",
        "    \"IndependentStatusInd\",\n",
        "    \"EconomicDisadvantageSTAS\",\n",
        "    \"CountryOfBirth\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1677083175373
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to convert categorical strings, booleans, or floats into ints ...\n",
            "ActualScore_KDC is re-casted from object as int\n",
            "Did not convert CountryOfBirth with dtype object. Showing top 5 value counts:\n",
            "1101     434288\n",
            "0003      54112\n",
            "Other     15272\n",
            "7105       2824\n",
            "2102       2104\n",
            "Name: CountryOfBirth, dtype: int64\n",
            "Did not convert Disability with dtype object. Showing top 5 value counts:\n",
            "N     455912\n",
            "Y      62112\n",
            "NA        32\n",
            "Name: Disability, dtype: int64\n",
            "Did not convert EconomicDisadvantageSTAS with dtype object. Showing top 5 value counts:\n",
            "N    338432\n",
            "Y    179624\n",
            "Name: EconomicDisadvantageSTAS, dtype: int64\n",
            "Did not convert Gender with dtype object. Showing top 5 value counts:\n",
            "M    265248\n",
            "F    252464\n",
            "X       216\n",
            "Z        72\n",
            "T        48\n",
            "Name: Gender, dtype: int64\n",
            "Did not convert IndependentStatusInd with dtype object. Showing top 5 value counts:\n",
            "N    512872\n",
            "Y      5184\n",
            "Name: IndependentStatusInd, dtype: int64\n",
            "Did not convert IndigenousStatusInd with dtype object. Showing top 5 value counts:\n",
            "NON-INDIGENOUS    429216\n",
            "INDIGENOUS         64896\n",
            "UNKNOWN            23944\n",
            "Name: IndigenousStatusInd, dtype: int64\n",
            "Did not convert InternationalStudentType with dtype object. Showing top 5 value counts:\n",
            "National           515320\n",
            "Dependent            2416\n",
            "Full Fee Paying       320\n",
            "Name: InternationalStudentType, dtype: int64\n",
            "Did not convert LaunchingIntoLearningInd with dtype object. Showing top 5 value counts:\n",
            "N     301056\n",
            "NA    209296\n",
            "Y       7704\n",
            "Name: LaunchingIntoLearningInd, dtype: int64\n",
            "ParentsHighestEducationLevel is re-casted from object as int\n",
            "ParentsHighestOccupationLevel is re-casted from object as int\n",
            "Did not convert PermanentResident with dtype object. Showing top 5 value counts:\n",
            "NA           505472\n",
            "Permanent     10544\n",
            "Temporary      2040\n",
            "Name: PermanentResident, dtype: int64\n",
            "Did not convert StudentHasActiveEduPointEnrolment with dtype object. Showing top 5 value counts:\n",
            "N    455872\n",
            "Y     62184\n",
            "Name: StudentHasActiveEduPointEnrolment, dtype: int64\n",
            "Did not convert StudentHasActiveTasTafeEnrolment with dtype object. Showing top 5 value counts:\n",
            "N    514096\n",
            "Y      3960\n",
            "Name: StudentHasActiveTasTafeEnrolment, dtype: int64\n",
            "Did not convert StudentTransitionPlanStatusYear10 with dtype object. Showing top 5 value counts:\n",
            "Not Started    358040\n",
            "APPROVED       133176\n",
            "Submitted       21400\n",
            "Started          5128\n",
            "INPROGRESS        240\n",
            "Name: StudentTransitionPlanStatusYear10, dtype: int64\n",
            "exclusionTotalDays_date2019 is re-casted from object as int\n",
            "suspensionExtensionTotalDays_date2019 is re-casted from object as int\n",
            "suspensionTotalDays_date2019 is re-casted from object as int\n",
            "integer-encoded columns: ['ADHD_cond', 'ALLERG_cond', 'ANAPH_cond', 'ANXIET_cond', 'ARTHRI_cond', 'ASPERG_cond', 'ASTHMA_cond', 'AUTISM_cond', 'BLADDE_cond', 'BLEED_cond', 'BLOOD_cond', 'BOWEL_cond', 'CEREBP_cond', 'CHROM_cond', 'CLEFT_cond', 'COELI_cond', 'CONST_cond', 'CROHN_cond', 'CROUP_cond', 'CYSTI_cond', 'DEPRES_cond', 'DERMAT_cond', 'DEVEL_cond', 'DI_cond', 'DIAB_cond', 'DIET_cond', 'DOCHOS_cond', 'DOWNS_cond', 'DYSLEX_cond', 'EAR_cond', 'EATING_cond', 'ECZEMA_cond', 'EHLERS_cond', 'EPILEP_cond', 'EYE_cond', 'FAINTD_cond', 'FEET_cond', 'GENERA_cond', 'GROM_cond', 'HEADAC_cond', 'HEARIN_cond', 'HEARTM_cond', 'HIP_cond', 'HRTCON_cond', 'HYPERM_cond', 'INTELL_cond', 'JOINT_cond', 'KIDNEY_cond', 'KNEE_cond', 'LUNG_cond', 'MEDICA_cond', 'MEDICN_cond', 'MIGR_cond', 'MOTSIC_cond', 'OCD_cond', 'OPPOSI_cond', 'OSGOOD_cond', 'OTHER_cond', 'PERMIS_cond', 'PERTHE_cond', 'PREM_cond', 'SCOL_cond', 'SEIZCO_cond', 'SKIN_cond', 'SLEEP_cond', 'SPEECH_cond', 'THYR_cond', 'TOURET_cond', 'VACC_cond', 'VISUAL_cond', 'allergy_alert', 'anaphylaxis_alert', 'anxiety_alert', 'asthma_alert', 'asthmatic_alert', 'bees_alert', 'cats_alert', 'dairy_alert', 'dustmites_alert', 'eczema_alert', 'eggs_alert', 'epilepsy_alert', 'gluten_alert', 'hayfever_alert', 'migraines_alert', 'mild_alert', 'nuts_alert', 'peanuts_alert', 'penicillan_alert', 'penicillin_alert', 'seizures_alert', 'sunscreen_alert', 'ventolin_alert']\n",
            "One-hot encoding these columns: ['Gender', 'Disability', 'LaunchingIntoLearningInd', 'IndigenousStatusInd', 'StudentTransitionPlanStatusYear10', 'StudentHasActiveTasTafeEnrolment', 'StudentHasActiveEduPointEnrolment', 'PermanentResident', 'InternationalStudentType', 'IndependentStatusInd', 'EconomicDisadvantageSTAS', 'CountryOfBirth']\n",
            "Number of labeled samples: 5226/55403\n",
            "Number of unlabeled samples: 50177/55403\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def one_hot_encode(df, columns, sensitive_columns=None):\n",
        "    if not columns:\n",
        "        return \n",
        "    print(\"One-hot encoding these columns:\", columns)\n",
        "    if not sensitive_columns:\n",
        "        sensitive_columns = []\n",
        "    \n",
        "    one_hot_map = {}\n",
        "    one_hot_dummies = []\n",
        "    for col in columns:\n",
        "        if df[col].dtypes != \"object\":\n",
        "            print(f\"{col} is not a string type. Double-check whether this should Top 5 values:\")\n",
        "            print(df[col].value_counts().head())\n",
        "        dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
        "        df = df.join(dummies)\n",
        "        dummy_cols = dummies.columns.tolist()\n",
        "        one_hot_dummies.extend(dummy_cols)  \n",
        "        one_hot_map[col] = dummy_cols\n",
        "        if col in sensitive_columns:\n",
        "            sensitive_columns.extend(dummy_cols)\n",
        "    df = df.drop(columns, axis=1)\n",
        "    sensitive_columns = [c for c in sensitive_columns if c not in columns]\n",
        "    return df, one_hot_map, one_hot_dummies, sensitive_columns\n",
        "\n",
        "\n",
        "def int_encode(df):\n",
        "    df[MEDICAL_CONDITION_COLS] = df[MEDICAL_CONDITION_COLS].apply(lambda x: x.map(MEDICAL_SERIOUSNESS)).fillna(NA_CONDITION_VALUE)\n",
        "    df[MEDICAL_ALERT_COLS] = df[MEDICAL_ALERT_COLS].apply(lambda x: x.map(MEDICAL_ALERTIND)).fillna(NA_ALERT_VALUE)\n",
        "    print(\"integer-encoded columns:\", MEDICAL_CONDITION_COLS+MEDICAL_ALERT_COLS)\n",
        "    return df            \n",
        "\n",
        "\n",
        "def get_encoded_feature_maps(encoded_feature_map, feature_map):\n",
        "    feature_names = []\n",
        "    inverse_feature_map = {}\n",
        "    new_feature_map = {}\n",
        "    for category, feature_cols in feature_map.items():\n",
        "        new_feature_cols = []\n",
        "        for c in feature_cols:\n",
        "            if c in encoded_feature_map:\n",
        "                encoded_feature_names = encoded_feature_map[c]\n",
        "                feature_names.extend(encoded_feature_names)\n",
        "                new_feature_cols.extend(encoded_feature_names) \n",
        "                for encoded in encoded_feature_names:\n",
        "                    inverse_feature_map[encoded] = category\n",
        "            else:\n",
        "                feature_names.append(c)\n",
        "                new_feature_cols.append(c) \n",
        "                inverse_feature_map[c] = category\n",
        "        new_feature_map[category] = new_feature_cols\n",
        "    return feature_names, new_feature_map, inverse_feature_map\n",
        "\n",
        "\n",
        "def convert_categorical_to_int(df, columns, exclude=None):\n",
        "    if exclude is None:\n",
        "        exclude = []\n",
        "    mask_boolean = df.dtypes == bool\n",
        "    mask_obj = df.dtypes == \"object\"\n",
        "    # these float columns should be casted as ints\n",
        "    mask_float_year = df.columns.str.contains(\"year\", case=False) & (df.dtypes == float)\n",
        "    mask_float_attendance = df.columns.isin(ATTENDANCE_COLS) & (df.dtypes == float)\n",
        "    mask_category = mask_obj | mask_boolean | mask_float_year | mask_float_attendance\n",
        "    categoricals = df.dtypes[mask_category].index.difference([STUDENT_ID]).tolist() \n",
        "    print(\"Attempting to convert categorical strings, booleans, or floats into ints ...\")\n",
        "    for c in categoricals:\n",
        "        if c in columns and c not in exclude:\n",
        "            try:\n",
        "                dtypes = df[c].dtypes\n",
        "                df[c] = df[c].astype(int)\n",
        "                print(f\"{c} is re-casted from {dtypes} as int\")\n",
        "            except:\n",
        "                print(f\"Did not convert {c} with dtype {dtypes}. Showing top 5 value counts:\")\n",
        "                print(df[c].value_counts().head())\n",
        "                continue    \n",
        "            \n",
        "    return df\n",
        "\n",
        "\n",
        "FEATURE_NAMES = [c for cols in FEATURE_MAP.values() for c in cols]\n",
        " \n",
        "assert set(FEATURE_NAMES).issubset(set(df.columns)), \"There are missing FEATURE_MAP columns from dataframe df!\" \n",
        "\n",
        "# attempting to convert numerical strings and booleans, and categorical floats into ints efficient training; assuming cardinality is not too large\n",
        "exclude = MEDICAL_CONDITION_COLS + MEDICAL_ALERT_COLS\n",
        "df = convert_categorical_to_int(df, columns=FEATURE_NAMES, exclude=exclude)\n",
        "\n",
        "# fill missing value in medical features\n",
        "df[MEDICAL_CONDITION_COLS + MEDICAL_ALERT_COLS] = df[MEDICAL_CONDITION_COLS + MEDICAL_ALERT_COLS].fillna(\"NA\") \n",
        "\n",
        "# integer-encode columns\n",
        "df = int_encode(df)\n",
        "\n",
        "# one-hot encode string columns\n",
        "df, ONE_HOT_MAP, ONE_HOT_ENCODE_COLS, SENSITIVE_COLUMNS = one_hot_encode(df, columns=ONE_HOT_ENCODE_COLS, sensitive_columns=SENSITIVE_COLUMNS)\n",
        "\n",
        "# update feature names and maps after encoding features\n",
        "FEATURE_NAMES, FEATURE_MAP, INVERSE_FEATURE_MAP = get_encoded_feature_maps(encoded_feature_map=ONE_HOT_MAP, feature_map=FEATURE_MAP) \n",
        "\n",
        "# deduplicates records by unique keys\n",
        "df = df.drop_duplicates(STUDENT_ID)\n",
        "\n",
        "# drop Grade 12 students since not sure why they have no labels\n",
        "# this warrants separate consideration for this group  \n",
        "df = df[df[\"YearLevelCode_current\"] != 12]\n",
        "\n",
        "\n",
        "# sanity check no missing values in features\n",
        "mask_missing_values = df[FEATURE_NAMES].isnull().any()\n",
        "missing_value_features = mask_missing_values[mask_missing_values].index\n",
        "if len(missing_value_features) > 0:\n",
        "    print(\"There are missing values in features per below! Double-check if this is intended. If so, then make sure your model handles missing values.\")\n",
        "    print(missing_value_features)\n",
        "    \n",
        "# sanity check that class 1 of binary target is defined as level of need 3 and 4 in multi-class target\n",
        "vul_miss_high_need = df[MULTICLASS_TARGET].isnull().equals(df[BINARY_TARGET].isnull())\n",
        "assert vul_miss_high_need, f\"{BINARY_TARGET} and {MULTICLASS_TARGET} have different missing values!\"\n",
        "vul_eq_high_need = df.loc[df[MULTICLASS_TARGET].notnull(), MULTICLASS_TARGET].isin([3, 4]) == df.loc[df[BINARY_TARGET].notnull(), BINARY_TARGET]\n",
        "if not vul_eq_high_need.all():\n",
        "    print(df.loc[(~vul_eq_high_need) & (df[MULTICLASS_TARGET].notnull()), [MULTICLASS_TARGET, BINARY_TARGET]])\n",
        "\n",
        "\n",
        "# define labels: BINARY_TARGET is a nullable float (1.0, 0.0 or NaN) for convenience; NOMINATION_TARGET is a boolean indicating assessment status (True or Falsee)\n",
        "df[NOMINATION_TARGET] = df[BINARY_TARGET].notnull()\n",
        "\n",
        "\n",
        "print(f\"Number of labeled samples: {sum(~df[BINARY_TARGET].isna())}/{len(df[BINARY_TARGET])}\")\n",
        "print(f\"Number of unlabeled samples: {sum(df[BINARY_TARGET].isna())}/{len(df[BINARY_TARGET])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1677083175585
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature category - Medical:\n",
            "['ADHD_cond', 'ALLERG_cond', 'ANAPH_cond', 'ANXIET_cond', 'ARTHRI_cond', 'ASPERG_cond', 'ASTHMA_cond', 'AUTISM_cond', 'BLADDE_cond', 'BLEED_cond', 'BLOOD_cond', 'BOWEL_cond', 'CEREBP_cond', 'CHROM_cond', 'CLEFT_cond', 'COELI_cond', 'CONST_cond', 'CROHN_cond', 'CROUP_cond', 'CYSTI_cond', 'DEPRES_cond', 'DERMAT_cond', 'DEVEL_cond', 'DI_cond', 'DIAB_cond', 'DIET_cond', 'DOCHOS_cond', 'DOWNS_cond', 'DYSLEX_cond', 'EAR_cond', 'EATING_cond', 'ECZEMA_cond', 'EHLERS_cond', 'EPILEP_cond', 'EYE_cond', 'FAINTD_cond', 'FEET_cond', 'GENERA_cond', 'GROM_cond', 'HEADAC_cond', 'HEARIN_cond', 'HEARTM_cond', 'HIP_cond', 'HRTCON_cond', 'HYPERM_cond', 'INTELL_cond', 'JOINT_cond', 'KIDNEY_cond', 'KNEE_cond', 'LUNG_cond', 'MEDICA_cond', 'MEDICN_cond', 'MIGR_cond', 'MOTSIC_cond', 'OCD_cond', 'OPPOSI_cond', 'OSGOOD_cond', 'OTHER_cond', 'PERMIS_cond', 'PERTHE_cond', 'PREM_cond', 'SCOL_cond', 'SEIZCO_cond', 'SKIN_cond', 'SLEEP_cond', 'SPEECH_cond', 'THYR_cond', 'TOURET_cond', 'VACC_cond', 'VISUAL_cond', 'allergy_alert', 'anaphylaxis_alert', 'anxiety_alert', 'asthma_alert', 'asthmatic_alert', 'bees_alert', 'cats_alert', 'dairy_alert', 'dustmites_alert', 'eczema_alert', 'eggs_alert', 'epilepsy_alert', 'gluten_alert', 'hayfever_alert', 'migraines_alert', 'mild_alert', 'nuts_alert', 'peanuts_alert', 'penicillan_alert', 'penicillin_alert', 'seizures_alert', 'sunscreen_alert', 'ventolin_alert', 'Autism', 'ECIS', 'HearingImpaired', 'IQ55_70', 'Intellectual', 'KinderSupport', 'Level1', 'Level2', 'Medical', 'Multiple', 'Physical', 'Psychiatric', 'VisionImpaired']\n",
            "Feature category - Demographic:\n",
            "['Gender_M', 'Gender_T', 'Gender_U', 'Gender_X', 'Gender_Z', 'EconomicDisadvantageSTAS_Y', 'Disability_NA', 'Disability_Y', 'IndigenousStatusInd_NON-INDIGENOUS', 'IndigenousStatusInd_UNKNOWN', 'IndependentStatusInd_Y', 'StudentATSIStatusAny_date2019', 'StudentInStateCareIndAny_date2019', 'ParentsHighestEducationLevel', 'ParentsHighestOccupationLevel', 'BirthMonth', 'BirthYear', 'CountryOfBirth_1100', 'CountryOfBirth_1101', 'CountryOfBirth_1201', 'CountryOfBirth_2100', 'CountryOfBirth_2102', 'CountryOfBirth_5204', 'CountryOfBirth_6101', 'CountryOfBirth_6203', 'CountryOfBirth_7102', 'CountryOfBirth_7103', 'CountryOfBirth_7105', 'CountryOfBirth_7201', 'CountryOfBirth_8104', 'CountryOfBirth_Other', 'PermanentResident_Permanent', 'PermanentResident_Temporary', 'InternationalStudentType_Full Fee Paying', 'InternationalStudentType_National', 'LaunchingIntoLearningInd_NA', 'LaunchingIntoLearningInd_Y', 'StudentHasActiveEduPointEnrolment_Y', 'StudentHasActiveTasTafeEnrolment_Y', 'StudentTransitionPlanStatusYear10_INPROGRESS', 'StudentTransitionPlanStatusYear10_Not Started', 'StudentTransitionPlanStatusYear10_PENDINGAPPROVAL', 'StudentTransitionPlanStatusYear10_Started', 'StudentTransitionPlanStatusYear10_Submitted', 'ProtectionOrderCount_Residency_ind_pre2020', 'ProtectionOrderCount_Contact_ind_pre2020', 'ProtectionOrderCount_Guardianship_ind_pre2020', 'ProtectionOrderCount_Action_Legal_ind_pre2020', 'ProtectionOrderCount_Action_Protection_ind_pre2020', 'ProtectionOrderCount_Child_Protection_ind_pre2020', 'ProtectionOrderCount_Action_StudentLegal_ind_pre2020', 'ProtectionOrderCount_FVO_ind_pre2020', 'ProtectionOrderCount_SACS_ind_pre2020', 'ProtectionOrderCount_Restraining_ind_pre2020', 'ProtectionOrderCount_Special_issues_ind_pre2020', 'ProtectionOrderCount_Interim_CPO_ind_pre2020']\n",
            "Feature category - Action:\n",
            "['Action_cnt_2019', 'wasExpulsed_date2019', 'suspensionExtensionCount_date2019', 'suspensionExtensionTotalDays_date2019', 'suspensionCount_date2019', 'suspensionTotalDays_date2019', 'exclusionCount_date2019', 'exclusionTotalDays_date2019', 'DisciplinarySanctionReasonCategoryAggregate_A_date2019', 'DisciplinarySanctionReasonCategoryAggregate_C_date2019', 'DisciplinarySanctionReasonCategoryAggregate_V_date2019', 'DisciplinarySanctionReasonCategoryAggregate_B_date2019', 'DisciplinarySanctionReasonCategoryAggregate_D_date2019', 'DisciplinarySanctionReasonCategoryAggregate_R_date2019', 'DisciplinarySanctionReasonCategoryAggregate_O_date2019', 'DisciplinarySanctionReasonCategoryAggregate_P_date2019', 'DisciplinarySanctionReasonCategoryAggregate_S_date2019', 'DisciplinarySanctionReasonCategoryAggregate_W_date2019', 'DisciplinarySanctionReasonCategoryAggregate_H_date2019']\n",
            "Feature category - Test:\n",
            "['ActualScore_latest_ACFEN', 'CalendarYear_latest_ACFEN', 'YearLevelCode_latest_ACFEN', 'ActualScore_latest_ACFMT', 'CalendarYear_latest_ACFMT', 'YearLevelCode_latest_ACFMT', 'ActualScore_KDC', 'CalendarYear_KDC']\n",
            "Feature category - Attendance:\n",
            "['sum_absentStreak']\n"
          ]
        }
      ],
      "source": [
        "for category, cols in FEATURE_MAP.items():\n",
        "    print(f\"Feature category - {category}:\")\n",
        "    print(cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Create proxy labels\n",
        "Proxy labels provide a way to add additional labels for nomination and students needing personalized support "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1677083175763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "distribution of proxy labels among all students: 1275 (2.3%)\n",
            "distribution of proxy labels among nominated students:\n",
            " 3.0    45\n",
            "2.0    34\n",
            "4.0    22\n",
            "1.0    20\n",
            "Name: LevelofNeed, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# define proxy labels based on expert opinions: \n",
        "# medical condition in serious or fatal categories (coded value 3 or 4)\n",
        "mask_fatal_or_serious_medical_cond = df[MEDICAL_CONDITION_COLS].isin([3, 4]).any(axis=1)\n",
        "n_proxy_added = mask_fatal_or_serious_medical_cond.sum()\n",
        "print(f\"distribution of proxy labels among all students: {n_proxy_added} ({n_proxy_added/df.shape[0]:.1%})\")\n",
        "print(\"distribution of proxy labels among nominated students:\\n\", df[mask_fatal_or_serious_medical_cond][MULTICLASS_TARGET].value_counts())\n",
        "\n",
        "# add proxy labels PROXY_TARGET and PROXY_NOMINATION_TARGET\n",
        "df[PROXY_TARGET] = df[BINARY_TARGET]\n",
        "df.loc[mask_fatal_or_serious_medical_cond, PROXY_TARGET] = 1\n",
        "df[PROXY_NOMINATION_TARGET] = df[PROXY_TARGET].notnull()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Disability_NA', 'Disability_Y', 'EconomicDisadvantageSTAS_Y']\n",
            "['Gender_M', 'Gender_T', 'Gender_U', 'Gender_X', 'Gender_Z', 'Disability_NA', 'Disability_Y', 'LaunchingIntoLearningInd_NA', 'LaunchingIntoLearningInd_Y', 'IndigenousStatusInd_NON-INDIGENOUS', 'IndigenousStatusInd_UNKNOWN', 'StudentTransitionPlanStatusYear10_INPROGRESS', 'StudentTransitionPlanStatusYear10_Not Started', 'StudentTransitionPlanStatusYear10_PENDINGAPPROVAL', 'StudentTransitionPlanStatusYear10_Started', 'StudentTransitionPlanStatusYear10_Submitted', 'StudentHasActiveTasTafeEnrolment_Y', 'StudentHasActiveEduPointEnrolment_Y', 'PermanentResident_Permanent', 'PermanentResident_Temporary', 'InternationalStudentType_Full Fee Paying', 'InternationalStudentType_National', 'IndependentStatusInd_Y', 'EconomicDisadvantageSTAS_Y', 'CountryOfBirth_1100', 'CountryOfBirth_1101', 'CountryOfBirth_1201', 'CountryOfBirth_2100', 'CountryOfBirth_2102', 'CountryOfBirth_5204', 'CountryOfBirth_6101', 'CountryOfBirth_6203', 'CountryOfBirth_7102', 'CountryOfBirth_7103', 'CountryOfBirth_7105', 'CountryOfBirth_7201', 'CountryOfBirth_8104', 'CountryOfBirth_Other']\n"
          ]
        }
      ],
      "source": [
        "# these column names are modified after one-hot encoding\n",
        "print(SENSITIVE_COLUMNS)\n",
        "print(ONE_HOT_ENCODE_COLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Modeling\n",
        "- Perform data balance analysis to choose resampling strategy\n",
        "- Run supervised learning learning pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1677083175937
        }
      },
      "outputs": [],
      "source": [
        "# sklearn imbalanced classification metrics\n",
        "scoring_metrics = [\"balanced_accuracy\", \"fbeta_weighted\", \"recall_weighted\", \"precision_weighted\", \"roc_auc\", \"accuracy\", \"fbeta\", \"recall\", \"precision\", \"average_precision\"]\n",
        "# suppress warning when DummyClassifier makes no positive predictions\n",
        "scoring = OrderedDict()\n",
        "for s in scoring_metrics:\n",
        "    # deal with errors when dummy prediction has only one class \n",
        "    if s in {\"precision_weighted\", \"precision\"}:\n",
        "        scorer = make_scorer(precision_score, average=\"weighted\" if s == \"precision_weighted\" else \"binary\", zero_division=0)\n",
        "    if s in {\"fbeta_weighted\", \"fbeta\"}:\n",
        "        scorer = make_scorer(fbeta_score, beta=F_SCORE_BETA, average=\"weighted\" if s == \"fbeta_weighted\" else \"binary\", zero_division=0)\n",
        "    else:\n",
        "        scorer = s\n",
        "    scoring[s] = scorer\n",
        "\n",
        "\n",
        "# fairness metrics\n",
        "fairness_metrics = {\n",
        "    \"selection rate\": selection_rate,\n",
        "    \"recall\": recall_score,\n",
        "    \"fbeta_score\": partial(fbeta_score, beta=F_SCORE_BETA, zero_division=0),\n",
        "    \"true positive rate\": true_positive_rate,\n",
        "    \"count\": count}\n",
        "\n",
        "\n",
        "def get_fairness_metrics_df(y_true, y_pred, sensitive_features, show=False):\n",
        "    # evaluate the performance of model fairness    \n",
        "    performance = MetricFrame(metrics=fairness_metrics,\n",
        "                            y_true=y_true,\n",
        "                            y_pred=y_pred,\n",
        "                            sensitive_features=sensitive_features)\n",
        "\n",
        "    if show:\n",
        "        performance.by_group.plot.bar(\n",
        "            subplots=True,\n",
        "            layout=[len(fairness_metrics), 1],\n",
        "            legend=False,\n",
        "            figsize=[5, 3 * len(fairness_metrics)],\n",
        "            title=\"Fairness metrics\"\n",
        "        )\n",
        "        plt.tight_layout(rect=(0, 0, 0.9, 0.9))\n",
        "        plt.show()\n",
        "\n",
        "    try: \n",
        "        result = pd.DataFrame({\"difference\": performance.difference(),\n",
        "                            \"ratio\": performance.ratio(),\n",
        "                            \"group_min\": performance.group_min(),\n",
        "                            \"group_max\": performance.group_max()}).T\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\")\n",
        "        print(e)\n",
        "        result = pd.DataFrame()\n",
        "    return result \n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def train_cv(X, y, seed=1, cv=None, search_hp=False, hp_grid=None, n_iter=10, scoring_metric=\"recall\", model_dict=None, greater_is_better=True):\n",
        "    if cv is None:\n",
        "        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=seed)    \n",
        "    \n",
        "    # set up a default set of models to run \n",
        "    if model_dict is None:\n",
        "        # to illustrate the imbalance problem, establish a dummy baseline\n",
        "        fixed_args = dict(random_state=seed, n_jobs=-1) \n",
        "        model_dict = {\n",
        "            \"Dummy\": DummyClassifier(strategy=\"most_frequent\"),\n",
        "            \"Logit\": skLogit(penalty=\"l1\", solver=\"liblinear\", random_state=seed),\n",
        "            \"RF\": RandomForestClassifier(oob_score=True, **fixed_args),\n",
        "            \"LGBM\": LGBMClassifier(verbose=-1, **fixed_args),\n",
        "            \"EBM\": ExplainableBoostingClassifier(**fixed_args),\n",
        "        }\n",
        "\n",
        "    # some models require early stopping so get a additional validation dataset  \n",
        "    X_train, X_valid, y_train_binary, y_valid = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y) \n",
        "    # set up default hyper-parameter grid for a set of models and fit parameters for specific models \n",
        "    fit_params_dict = {}\n",
        "    if hp_grid is None:\n",
        "        hp_grid = {\n",
        "            \"Logit\": {\"C\": [1e-2, 1]},\n",
        "            \"RF\": {\"n_estimators\": [100, 500, 1000], \"max_depth\": [None, 2, 5]},\n",
        "            \"LGBM\": {\"n_estimators\": [100, 500, 1000], \"max_depth\": [-1, 2, 5], \"learning_rate\": loguniform(1e-5, 1e-1)},\n",
        "            \"EBM\": {\"inner_bags\": [0], \"max_leaves\": [3, 32]},\n",
        "        }\n",
        "        # LGBM requires early stopping to avoid overfitting\n",
        "        fit_params_dict = {\n",
        "            \"LGBM\": {\"early_stopping_rounds\": 20, \"eval_set\": [(X_valid, y_valid)]}\n",
        "        }\n",
        "\n",
        "    \n",
        "    # store performance results \n",
        "    hp_results = {}\n",
        "    for model_label, model in model_dict.items():\n",
        "        # require pandas output format to use strings as categorical features in the model args\n",
        "        pipeline = pipeline_with_sampler([(model_label, model)])\n",
        "        start = time.time()\n",
        "        # dummy classifier skips resampling and hp search\n",
        "        if isinstance(pipeline.steps[-1][1], DummyClassifier):\n",
        "            result = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, return_estimator=True, return_train_score=True)\n",
        "            hp_results[model_label] = [(0, result)]\n",
        "        else:\n",
        "            # LGBM requires early stopping to avoid overfitting\n",
        "            if model_label == \"LGBM\":\n",
        "                X_, y_ = X_train, y_train_binary \n",
        "            else:\n",
        "                X_, y_ = X, y\n",
        "                \n",
        "            # add resampling methods to pipelines\n",
        "            if UNDERSAMPLE_RATIO is not None:\n",
        "                pipeline.steps.insert(0, (\"undersampling\", RandomUnderSampler(sampling_strategy=UNDERSAMPLE_RATIO, random_state=seed)))\n",
        "            if OVERSAMPLE_RATIO is not None:\n",
        "                pipeline.steps.insert(0, (\"oversampling\", RandomOverSampler(sampling_strategy=OVERSAMPLE_RATIO, random_state=seed)))\n",
        "           \n",
        "            param_grid = hp_grid.get(model_label, None)\n",
        "            param_iterator = ParameterSampler(param_grid, n_iter=n_iter, random_state=seed)\n",
        "            fit_params = fit_params_dict.get(model_label, None)\n",
        "            if fit_params:\n",
        "                fit_params = {f\"{pipeline.steps[-1][0]}__{k}\": v for k, v in fit_params.items()}\n",
        "\n",
        "            def cv_helper(pipeline):\n",
        "                # fit cv  \n",
        "                result = cross_validate(pipeline, X=X_, y=y_, cv=cv, scoring=scoring, return_estimator=True, return_train_score=True, fit_params=fit_params)\n",
        "                score = np.mean(result[f\"test_{scoring_metric}\"])\n",
        "                # store results\n",
        "                if model_label not in hp_results:\n",
        "                    hp_results[model_label] = [(score, result)]\n",
        "                else:\n",
        "                    hp_results[model_label].append((score, result))\n",
        "            \n",
        "            # if search_hp is True, perform search over parameter grid\n",
        "            if search_hp:\n",
        "               for idx, param in enumerate(param_iterator):\n",
        "                    # update model parameter for each hyperparameter set\n",
        "                    pipeline.steps[-1][1].set_params(**param)\n",
        "                    cv_helper(pipeline)\n",
        "            # otherwise, train with default parameters \n",
        "            else:\n",
        "                cv_helper(pipeline)\n",
        "        model_time = time.time() - start\n",
        "        print(f\"Training {model_label} takes {model_time:.2f} seconds\")\n",
        "        \n",
        "    # cv_results contains the best hp search results\n",
        "    cv_results = {model_label: sorted(hp_results[model_label], key=lambda tup: tup[0], reverse=greater_is_better)[0][1] for model_label in model_dict}\n",
        "    return cv_results\n",
        "\n",
        "\n",
        "def evaluate_cv(cv_results, X_test, y_test, show=False):\n",
        "    valid_score_cols = [\"test_{}\".format(score) for score in scoring]\n",
        "    valid_scores = pd.DataFrame({k: [v[c].mean() for c in valid_score_cols] for k, v in cv_results.items()}, index=valid_score_cols).T\n",
        "    valid_scores.columns = valid_scores.columns.str.replace(\"test_\", \"\")\n",
        "\n",
        "    # define evaluation set\n",
        "    test_scores = pd.DataFrame()\n",
        "    if X_test is not None and y_test is not None:\n",
        "        test_scores = OrderedDict()\n",
        "        for model_label, cv_result in cv_results.items():\n",
        "            cv_test_score = []\n",
        "            for idx, estimator in enumerate(cv_result[\"estimator\"]):\n",
        "                y_pred = estimator.predict_proba(X_test)[:, 1]\n",
        "                score = evaluate(y_test, y_pred, model_label=model_label, show=show)\n",
        "                cv_test_score.append(score)\n",
        "            test_scores[model_label] = pd.concat(cv_test_score).mean(0)\n",
        "        test_scores = pd.DataFrame(test_scores).T\n",
        "    return valid_scores, test_scores\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred, model_label=None, decision_threshold=0.5, show=SHOW, y_pred_is_proba=True):\n",
        "    if y_pred_is_proba:\n",
        "        target_pred = y_pred > decision_threshold\n",
        "    else:\n",
        "        target_pred = y_pred\n",
        "    bac = balanced_accuracy_score(y_true, target_pred)\n",
        "    precision, recall, fbeta, _ = precision_recall_fscore_support(y_true, target_pred, beta=F_SCORE_BETA, average=\"weighted\", zero_division=0)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred) \n",
        "    if show:\n",
        "        print(\"Classification report:\")\n",
        "        print(classification_report(y_true, target_pred))\n",
        "        figure, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        ConfusionMatrixDisplay.from_predictions(y_true, target_pred, ax=axes[0])\n",
        "        axes[0].set_title(f\"Confusion matrix: {model_label}\") \n",
        "        PrecisionRecallDisplay.from_predictions(y_true, y_pred, ax=axes[1])\n",
        "        axes[1].set_title(f\"Precision-recall curve: {model_label}\")\n",
        "        RocCurveDisplay.from_predictions(y_true, y_pred, ax=axes[2])\n",
        "        axes[2].set_title(f\"ROC curve: {model_label}\")\n",
        "        plt.tight_layout(rect=(0, 0, 0.9, 0.9))\n",
        "        plt.show()\n",
        "\n",
        "    values = [bac, fbeta, recall, precision, roc_auc]\n",
        "    ac = accuracy_score(y_true, target_pred)\n",
        "    precision, recall, fbeta, _ = precision_recall_fscore_support(y_true, target_pred, beta=F_SCORE_BETA, average=\"binary\", zero_division=0)\n",
        "    ap = average_precision_score(y_true, y_pred)\n",
        "    values += [ac, fbeta, recall, precision, ap]\n",
        "    scores = dict(zip(list(scoring.keys()), values))\n",
        "    return pd.DataFrame(scores, index=[0])\n",
        "\n",
        "\n",
        "wrap_ticks = lambda x: textwrap.fill(x.get_text(), 20)\n",
        "\n",
        "\n",
        "def plot_balance(label_dist):\n",
        "    colors = [\"grey\", \"brown\", \"green\", \"orange\", \"red\"]\n",
        "    binary_colors = [\"grey\", \"red\"]\n",
        "    for normalize in [True, False]:\n",
        "\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(8, 5))\n",
        "        axes = axes.flat\n",
        "        for idx, (title, values) in enumerate(label_dist.items()):\n",
        "            if \"need\" in title:\n",
        "                # label un-nominated/un-assessed students\n",
        "                plot_obj = values.astype(\"Int64\").fillna(-1).value_counts(normalize=normalize).sort_index()\n",
        "                color = binary_colors\n",
        "                labels = [\"otherwise\", \"needing personalized support\"]\n",
        "            else:\n",
        "                # label un-nominated/un-assessed students\n",
        "                plot_obj = values.astype(\"Int64\").fillna(-1).value_counts(normalize=normalize).sort_index()\n",
        "                plot_obj.rename(index={-1:\"un-nominated\"}, inplace=True) \n",
        "                color = colors[:] \n",
        "                # print(plot_obj)\n",
        "                labels = plot_obj.index\n",
        "                if \"imputed\" in title:\n",
        "                    color = color[1:]\n",
        "            measure = [\"counts\", \"proportions\"][normalize]\n",
        "            plot_obj.plot.bar(ax=axes[idx], title=title + f\" (train) {measure}\" , stacked=True, color=color)\n",
        "            if normalize:\n",
        "                axes[idx].set_ylim(0, 1)\n",
        "            \n",
        "            axes[idx].set_xticklabels(labels, rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "def convert_to_shap_interaction_values(main_effects, interaction_effects, interaction_col_delimiter=\" x \"):\n",
        "    \"\"\"\n",
        "    main_effects: data frame of shape (n_samples, n_features)\n",
        "    interaction_effects: data frame of shape (n_samples, n_pairwise_interactions)\n",
        "    N: number of examples\n",
        "    K: number of features\n",
        "    \"\"\"\n",
        "    n_samples = main_effects.shape[0] \n",
        "    n_features = main_effects.shape[1]\n",
        "    feature_names = main_effects.columns.tolist()\n",
        "    assert isinstance(main_effects, pd.DataFrame), \"main effect must be a data frame with feature names\"\n",
        "    shap_interaction_values = np.zeros((n_samples, n_features, n_features))\n",
        "    # fill main effects along the diagonal of each example i out of N\n",
        "    np.einsum(\"ijj->ij\", shap_interaction_values)[...] = main_effects\n",
        "    error = shap_interaction_values.sum(1).sum(1) - main_effects.sum(1)\n",
        "    if not interaction_effects.empty:\n",
        "        # fill interaction effect off the diagonal matrix for pair of interactions\n",
        "        get_feature_index = lambda x: feature_names.index(x)\n",
        "        for pair in interaction_effects.columns:\n",
        "            i, j = map(get_feature_index, pair.split(interaction_col_delimiter))\n",
        "            # split the interaction effect equally into each order to match SHAP values\n",
        "            shap_interaction_values[:, i, j] = interaction_effects[pair] * 0.5 \n",
        "            shap_interaction_values[:, j, i] = interaction_effects[pair] * 0.5\n",
        "        error -= interaction_effects.sum(1) \n",
        "    assert ~np.isnan(error).any(), \"there is nan in EBM contr to shap interaction values! Check interaction terms. Possible solution: turn off interaction term.\"\n",
        "    if np.max(np.abs(error)) > 1e-6:\n",
        "        print(\"there is floating point error in converting EBM contr to shap interaction values!\")\n",
        "    return shap_interaction_values\n",
        "\n",
        "\n",
        "def get_estimator(pipeline):\n",
        "    estimator = pipeline\n",
        "    if hasattr(pipeline, \"steps\"):\n",
        "        estimator = pipeline.steps[-1][1]\n",
        "    return estimator \n",
        "\n",
        "\n",
        "def explain(X, cv_results):\n",
        "    \"\"\"\n",
        "    X: features to explain. \n",
        "    y: label column. It is optional: if provided, will use X and y to refit a logit model   \n",
        "    cv_results: a dictionary of the estimators Logit, LGBM, RF, EBM, or all of the above. RF and LGBM explanations use shap implementation of SHAP values.\n",
        "    index_map: a dataframe that maps from integer index to meaningful index columns such as student ids\n",
        "    show: controls visualization for feature contributions \n",
        "    \"\"\"\n",
        "    # explain the drivers for predictions in three models: logit, lgbm, ebm\n",
        "    # if any one of the conditional models fails, its feature importance vector will be nan \n",
        "\n",
        "    contr_dict = {}\n",
        "    for model_label in cv_results:    \n",
        "        try: \n",
        "            explain_output = None\n",
        "            model_pipeline = cv_results[model_label][\"estimator\"][0]\n",
        "            if model_label == \"logit\":\n",
        "                explain_output = explain_logit(X, model_pipeline)\n",
        "            elif model_label in [\"LGBM\", \"RF\", \"XGB\"]:\n",
        "                explain_output = explain_tree(X, model_pipeline)\n",
        "            elif model_label == \"EBM\":\n",
        "                explain_output = explain_ebm(X, model_pipeline)\n",
        "\n",
        "            if explain_output is not None:\n",
        "                contr_dict[model_label] = explain_output\n",
        "        except Exception as e:\n",
        "            print(f\"Explaining {model_label} failed for this error:\")\n",
        "            print(e)\n",
        "    return contr_dict\n",
        "\n",
        "\n",
        "def explain_logit(X, logit_pipeline):\n",
        "    # logit explanation\n",
        "    X_intercept = X.astype(float).copy()\n",
        "    X_intercept[\"intercept\"] = 1\n",
        "    logit_model = get_estimator(logit_pipeline)\n",
        "    coef = pd.Series(np.append(logit_model.coef_, logit_model.intercept_), index=FEATURE_NAMES + [\"intercept\"])\n",
        "    logit_contr = X_intercept.multiply(coef)\n",
        "    logit_pred_proba = add_prediction(logit_model, feature_datasets=[X])\n",
        "    return (logit_contr, logit_pred_proba)\n",
        "\n",
        "\n",
        "def explain_tree(X, tree_pipeline):\n",
        "    # shap explanation\n",
        "    tree_model = get_estimator(tree_pipeline)\n",
        "    assert tree_model.classes_[1], \"First position of classes must be True!\"\n",
        "    print(f\"Generating shap values for {tree_model}. This may take a while ...\")\n",
        "    X_ = X\n",
        "    if isinstance(tree_model, RandomForestClassifier) and N_RF_SAMPLES_TO_EXPLAIN is not None:\n",
        "        X_ = X.sample(N_RF_SAMPLES_TO_EXPLAIN, random_state=SEED)\n",
        "    start = time.time()\n",
        "    explainer = fasttreeshap.TreeExplainer(tree_model, algorithm=\"v2\", n_jobs=-1, shortcut=False)\n",
        "    tree_explanations = explainer(X_, check_additivity=False)\n",
        "    time_spent = time.time() - start\n",
        "    print(f\"Time spent on explaining {tree_model}: {time_spent:.2f} seconds\")\n",
        "    tree_shap_values = tree_explanations.values\n",
        "    base_values =  tree_explanations.base_values\n",
        "    if len(tree_shap_values.shape) == 3 and len(base_values.shape) == 2:\n",
        "        tree_shap_values = tree_shap_values[:, :, 1]\n",
        "        base_values = base_values[:, 1]\n",
        "    tree_contr = pd.DataFrame(tree_shap_values, columns=FEATURE_NAMES, index=X_.index)\n",
        "    tree_contr[\"intercept\"] = base_values\n",
        "    tree_pred_proba = add_prediction(tree_model, [X_])\n",
        "    return (tree_contr, tree_pred_proba)   \n",
        "\n",
        "\n",
        "def explain_ebm(X, ebm_pipeline):\n",
        "    ebm_model = get_estimator(ebm_pipeline)\n",
        "    assert ebm_model.classes_[1], \"position 1 is not the true label!\"\n",
        "    _, ebm_contr = ebm_model.predict_and_contrib(X)\n",
        "    ebm_features = ebm_model.feature_names\n",
        "    interaction_col_delimiter = \" x \"\n",
        "    # if ebm_features is None, this is a workaround for breaking change in interpret 0.3.0 \n",
        "    # see https://github.com/interpretml/interpret/issues/388\n",
        "    if ebm_features is None:\n",
        "        ebm_features = ebm_model.term_names_\n",
        "        interaction_col_delimiter = \" & \"\n",
        "    ebm_contr = pd.DataFrame(ebm_contr, columns=ebm_features, index=X.index)\n",
        "    main_effects = ebm_contr[ebm_features[:X.shape[1]]]\n",
        "    interaction_effects = ebm_contr[ebm_features[X.shape[1]:]]\n",
        "    if not interaction_effects.empty: \n",
        "        assert interaction_effects.notnull().all().all(), \"Found nan in EBM interaction terms, possibly due to EBM\\\"s inability to handle categorical interaction terms. Try turnning off interaction terms in EBM.\"\n",
        "    shap_interaction_values = convert_to_shap_interaction_values(main_effects, interaction_effects, interaction_col_delimiter=interaction_col_delimiter)\n",
        "    # sum over axis=1 computes total effect of SHAP values\n",
        "    ebm_contr = pd.DataFrame(shap_interaction_values.sum(axis=1), columns=main_effects.columns, index=X.index)\n",
        "    ebm_contr[\"intercept\"] = ebm_model.intercept_.item()\n",
        "    ebm_pred_proba = add_prediction(ebm_model, [X])\n",
        "    return (ebm_contr, ebm_pred_proba)\n",
        "\n",
        "\n",
        "def verify_explanations(contr_dict,  num_features_to_examine=5, index_map=None, delta=1e-2, show=SHOW):\n",
        "    # add index and column information to model contributions; and optionally visualize them \n",
        "    explanation_dict = {}\n",
        "    for model_label, (contr, pred_proba) in contr_dict.items():\n",
        "        if contr is None: \n",
        "            continue\n",
        "        sum_contr = contr.sum(1).apply(sigmoid)\n",
        "        if sum_contr.corr(pred_proba) < (1-delta) or (not sum_contr.equals(pred_proba)):\n",
        "            print(f\"{model_label} local accuracy may have precision issues!\")\n",
        "        contr_imp = contr.abs().mean().sort_values(ascending=False).drop(\"intercept\")\n",
        "        top_k_features = contr_imp.head(num_features_to_examine).index.tolist()\n",
        "\n",
        "        # add back meaningful index keys for data rows\n",
        "        if index_map is not None:\n",
        "            index_columns = index_map.columns.tolist()\n",
        "            contr = contr.merge(index_map, left_index=True, right_index=True)\n",
        "            contr = contr.set_index(index_columns)\n",
        "            \n",
        "        # add multilevel index to categorize feature importance\n",
        "        if contr.columns.nlevels == 1:\n",
        "            inverse_map = {\"intercept\": \"Intercept\", **INVERSE_FEATURE_MAP}\n",
        "            column_formatter = lambda x: inverse_map.get(x, \"Interactions\")\n",
        "            categories = contr.columns.map(column_formatter).fillna(\"Others\")\n",
        "            contr.columns = pd.MultiIndex.from_arrays([categories, contr.columns], names=[\"Category\", \"Feature\"])\n",
        "        \n",
        "        if show:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "            ax = axes[0]\n",
        "            contr_imp[top_k_features].plot.bar(ax=ax, rot=20)\n",
        "            ax.set_title(f\"Average Magnitude of Top {num_features_to_examine} {model_label} Feature Contributions\")\n",
        "            ax.set_ylabel(\"log-odds\")\n",
        "            ax.set_xticklabels(map(wrap_ticks, ax.get_xticklabels()))\n",
        "            ax = axes[1]\n",
        "            agg_contr_imp = contr.groupby(level=0, axis=1).sum().abs().mean().sort_values(ascending=False).drop(\"Intercept\")\n",
        "            agg_contr_imp.plot.bar(ax=ax, rot=20)\n",
        "            ax.set_title(f\"Average Magnitude of {model_label} Feature Contributions by Categories\")\n",
        "            ax.set_ylabel(\"log-odds\")\n",
        "            ax.set_xticklabels(map(wrap_ticks, ax.get_xticklabels()))\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        \n",
        "        explanation_dict[model_label] = contr \n",
        "\n",
        "    if len(explanation_dict) == 0:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    explanations = pd.concat(explanation_dict)\n",
        "    return explanations\n",
        "    \n",
        "\n",
        "def add_prediction(model, feature_datasets):\n",
        "    predictions = []\n",
        "    for X in feature_datasets:\n",
        "        if X is None: continue\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            assert model.classes_[1], \"class 1 is not the model predicted class!\"\n",
        "            pred = pd.Series(model.predict_proba(X)[:, 1])\n",
        "        else:\n",
        "            pred = pd.Series(model.predict(X))\n",
        "        pred.index = X.index\n",
        "        predictions.append(pred)\n",
        "    pred_nominated = pd.concat(predictions)\n",
        "    return pred_nominated\n",
        "\n",
        "\n",
        "def define_train_test_set(df, use_balance_sample=True, use_unnominated_only=False, disable_test_set=False, label=BINARY_TARGET):\n",
        "    \n",
        "    mask_need = df[label] == 1 # only those which were assessed and needed to be assessed\n",
        "    mask_unnominated = df[label].isnull()\n",
        "\n",
        "    if use_balance_sample:\n",
        "        mask = ~mask_need\n",
        "        mask_label = \"mix of un-nominated and no need for personalized support\"\n",
        "        if use_unnominated_only:\n",
        "            mask = mask_unnominated\n",
        "            mask_label = \"un-nominated\"\n",
        "        unnominated = df.loc[mask].sample(sum(mask_need), random_state=SEED)\n",
        "        nominated = df[mask_need]\n",
        "        dataset_to_use = pd.concat([unnominated, nominated])\n",
        "        # assume no nomination means no need for personalized support\n",
        "        dataset_to_use[BINARY_TARGET] = dataset_to_use[BINARY_TARGET].fillna(0)\n",
        "        print(f\"From {df.shape[0]} students, sampled {dataset_to_use.shape[0]} = {unnominated.shape[0]} {mask_label} + {nominated.shape[0]} assessed\")\n",
        "    else:\n",
        "        # in our new formulations, we define train-test set on the entire dataset including un-nominated students (the majority in this dataset) \n",
        "        dataset_to_use = df\n",
        "\n",
        "    features, labels = dataset_to_use[FEATURE_NAMES], dataset_to_use[label]\n",
        "    X_train, X_test, y_train_binary, y_test_binary = train_test_split(features, labels, test_size=0.20, random_state=SEED)\n",
        "    if disable_test_set:\n",
        "        X_train, X_test, y_train_binary, y_test_binary = features, None, labels, None\n",
        "        print(\"Disabled test set. Train data shape:\", X_train.shape, f\" positive label pct {y_train_binary.mean():.2%}\")\n",
        "    else:\n",
        "        print(f\"Train data shape:\", X_train.shape,  f\" positive label pct {y_train_binary.mean():.2%}\")\n",
        "        print(f\"Validation/test data shape:\", X_test.shape,  f\" positive label pct {y_test_binary.mean():.2%}\")\n",
        "    return dataset_to_use, X_train, X_test, y_train_binary, y_test_binary\n",
        "\n",
        "\n",
        "def evaluate_dataset(model_labels, target_label, dataset, data_subset_labels=None):\n",
        "    if data_subset_labels is None:\n",
        "        data_subset_labels = [\"train\", \"test\"]\n",
        "    # evaluate nomination predictions against labels \n",
        "    model_accuracy_scores = {}\n",
        "    model_fairness_scores = {}\n",
        "    for model_label in model_labels:\n",
        "        start = time.time()\n",
        "        # evaluate train-test performance on accuracy and fairness\n",
        "        accuracy_scores = {}\n",
        "        fairness_scores = {}\n",
        "        for data_subset_label in data_subset_labels:\n",
        "            data_subset = dataset.loc[dataset[\"dataset\"] == data_subset_label]\n",
        "            y_true = data_subset[target_label]\n",
        "            y_pred = data_subset[f\"{target_label}{model_label}Proba\"]\n",
        "            \n",
        "            # compute accuracy performance metrics\n",
        "            target_pred = y_pred > 0.5\n",
        "            perf_label = f\"supervised {data_subset_label}\\n{model_label}\"\n",
        "            print(f\"{perf_label} data has {y_true.shape[0]} rows with {y_true.sum()} class 1 ({y_true.mean():.2%})\")\n",
        "            score = evaluate(y_true, y_pred, model_label=perf_label)\n",
        "            accuracy_scores[data_subset_label] = score\n",
        "\n",
        "            # compute fairness metrics for each sensitive feature\n",
        "            fairness_by_feature = {}\n",
        "            # get unmitigated summary\n",
        "            for sensitive_col in SENSITIVE_COLUMNS:\n",
        "                fairness_summary = get_fairness_metrics_df(y_true=y_true, y_pred=target_pred, sensitive_features=data_subset[sensitive_col], show=SHOW)\n",
        "                fairness_by_feature[sensitive_col] = fairness_summary\n",
        "            fairness_scores[data_subset_label] = pd.concat(fairness_by_feature)\n",
        "        time_spent = time.time() - start\n",
        "        print(f\"Evaluating {model_label} on accuracy and fairness takes {time_spent:.2f} seconds\")\n",
        "        model_accuracy_scores[model_label] = pd.concat(accuracy_scores).reset_index(level=-1, drop=True)\n",
        "        model_fairness_scores[model_label] = pd.concat(fairness_scores)\n",
        "\n",
        "    model_accuracy_scores = pd.concat(model_accuracy_scores)\n",
        "    model_fairness_scores = pd.concat(model_fairness_scores)\n",
        "    \n",
        "    return model_accuracy_scores, model_fairness_scores\n",
        "\n",
        "\n",
        "def run_basic_pipeline(df, model_dict=None, use_balance_sample=True, use_unnominated_only=False, label=BINARY_TARGET, disable_test_set=False, seed=1):\n",
        "    \"\"\"\n",
        "    a pipeline consists of\n",
        "        - plot label balance  \n",
        "        - train predictive models\n",
        "        - print validation and test performance metrics\n",
        "        - plot global explanations\n",
        "    method: str that indicates a methodology \n",
        "    label: the target columns to predict\n",
        "    seed: the random seed to control train-test split\n",
        "    return: a tuple of a model object (or a list of them) and a pandas DataFrame with a column predicting the target\n",
        "    \"\"\"\n",
        "    # store results in a dictionary\n",
        "    results = {}\n",
        "\n",
        "    # define train/test feature/label dataset\n",
        "    dataset_to_use, X_train, X_test, y_train_binary, y_test_binary = define_train_test_set(\n",
        "        df=df, use_balance_sample=use_balance_sample, use_unnominated_only=use_unnominated_only, label=label, disable_test_set=disable_test_set)\n",
        "\n",
        "    # plot label distribution\n",
        "    label_dist = {\n",
        "        f\"{MULTICLASS_TARGET} distribution\": dataset_to_use[MULTICLASS_TARGET],\n",
        "        f\"{label} label distribution\": y_train_binary, \n",
        "    }\n",
        "    if SHOW:\n",
        "        plot_balance(label_dist=label_dist)\n",
        "\n",
        "    student_need_dist = dataset_to_use[MULTICLASS_TARGET].fillna(-1)\n",
        "    results[\"label_distr_pct\"] = student_need_dist.value_counts(normalize=True)\n",
        "    results[\"label_distr_cnt\"] = student_need_dist.value_counts()\n",
        "\n",
        "    # train a number of models (sklearn pipelines) in cross-validation fashion\n",
        "    cv_results = train_cv(X_train, y_train_binary, model_dict=model_dict, seed=seed, search_hp=SEARCH_HP)\n",
        "\n",
        "    # report the validation and test scores \n",
        "    valid_scores, test_scores = evaluate_cv(cv_results, X_test, y_test_binary) \n",
        "    results[\"validation_scores\"] = valid_scores\n",
        "    results[\"test_scores\"] = test_scores\n",
        "\n",
        "    # explain the models\n",
        "    explanation_dict = explain(dataset_to_use[FEATURE_NAMES], cv_results=cv_results)\n",
        "    local_explanations = verify_explanations(explanation_dict, num_features_to_examine=5, index_map=dataset_to_use[[STUDENT_ID]])\n",
        "    \n",
        "    if not local_explanations.empty:\n",
        "        global_explanations = local_explanations.droplevel(level=0, axis=1).abs().groupby(level=0, axis=0).mean().T\n",
        "        imp_cosine_similarity = global_explanations.loc[FEATURE_NAMES].corr(method=lambda x, y: x.dot(y)/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
        "        imp_cosine_similarity = pd.concat({\"Explanation Agreement (Cosine Similarity)\": imp_cosine_similarity}, axis=1)\n",
        "        results[\"feature_importance\"] = local_explanations\n",
        "        results[\"explanation_similarity\"] = imp_cosine_similarity\n",
        "\n",
        "    # gather the model results\n",
        "    for model_label in cv_results:\n",
        "        model = cv_results[model_label][\"estimator\"][0] \n",
        "        feature_datasets = (X_train, X_test)\n",
        "        dataset_to_use[f\"{label}{model_label}Proba\"] = add_prediction(model, feature_datasets=feature_datasets)\n",
        "    results[\"predicted_data\"] = dataset_to_use\n",
        "    results[\"cv_results\"] = cv_results\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_supervised_learning_on_nomination(df, model_dict=None, use_proxy_label=True, seed=1):\n",
        "    \"\"\"train on entire dataset predicting nomination status\"\"\"\n",
        "    pipeline_results = {}\n",
        "    df = df.copy()\n",
        "    \n",
        "    # apply train-test split on the full dataset \n",
        "    df[NOMINATION_TARGET] = df[BINARY_TARGET].notnull()\n",
        "    df[PROXY_NOMINATION_TARGET] = df[PROXY_TARGET].notnull()\n",
        "    train, test = train_test_split(df, test_size=0.20, random_state=seed)\n",
        "\n",
        "    # build nomination model and apply predictions\n",
        "    target_label = PROXY_NOMINATION_TARGET if use_proxy_label else NOMINATION_TARGET\n",
        "    nomination_results = run_basic_pipeline(df=train, model_dict=model_dict, use_balance_sample=False, disable_test_set=False, label=target_label)\n",
        "    for model_label, cv_result in nomination_results[\"cv_results\"].items():\n",
        "        model = cv_result[\"estimator\"][0]\n",
        "        for temp in [train, test]:\n",
        "            nomination_pred_label = f\"{target_label}{model_label}Proba\"\n",
        "            temp[nomination_pred_label] = add_prediction(model, feature_datasets=[temp[FEATURE_NAMES]])\n",
        "\n",
        "    # combine train and test set back into the result dataframe\n",
        "    combined_data = pd.concat([train, test])\n",
        "    combined_data[\"dataset\"] = combined_data.index.isin(train.index)\n",
        "    combined_data[\"dataset\"] = combined_data[\"dataset\"].map({True: \"train\", False:\"test\"})\n",
        "\n",
        "    # evaluate marginal need predictions against labels \n",
        "    model_labels = list(nomination_results[\"cv_results\"].keys()) \n",
        "    model_accuracy_scores, model_fairness_scores = evaluate_dataset(\n",
        "        model_labels=model_labels, dataset=combined_data, target_label=target_label)\n",
        "\n",
        "    # explain models\n",
        "    explanation_dict = explain(combined_data[FEATURE_NAMES], cv_results=nomination_results[\"cv_results\"])\n",
        "    local_explanations = verify_explanations(explanation_dict, num_features_to_examine=5, index_map=combined_data[[STUDENT_ID]])\n",
        "    \n",
        "    pipeline_results[\"accuracy_scores\"] = model_accuracy_scores\n",
        "    pipeline_results[\"fairness_scores\"] = model_fairness_scores\n",
        "    pipeline_results[\"predicted_data\"] = combined_data\n",
        "    pipeline_results[\"nomination_results\"] = nomination_results\n",
        "    pipeline_results[\"feature_importance\"] = local_explanations\n",
        "    return pipeline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Resampling analysis\n",
        "- compare the impact of resampling strategies on results \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1677083176145
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "model_label = \"RF\"\n",
        "model = RandomForestClassifier(oob_score=True, verbose=0, random_state=SEED)\n",
        "seed = 1\n",
        "\n",
        "fold_idx = 0 # pick a model for a random fold in k-fold validation\n",
        "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=seed)    \n",
        "pipeline_labels = [\"SQ\", \"undersample\", \"oversample+undersample\"]\n",
        "\n",
        "def compare_resampling_strategy(df, target_feature, feature_names=None, train_size=1):\n",
        "    if feature_names is None:\n",
        "        feature_names = FEATURE_NAMES\n",
        "    train, test = train_test_split(df, test_size=0.2, random_state=seed)\n",
        "    if train_size < 1:\n",
        "        train = train.sample(int(train_size * train.shape[0]), random_state=seed)\n",
        "    X_train, y_train = train[feature_names], train[target_feature].fillna(0).astype(int)\n",
        "\n",
        "    pipelines = []\n",
        "    pipeline = pipeline_with_sampler([(model_label, model)])\n",
        "    pipelines += [deepcopy(pipeline)]\n",
        "    pipeline.steps.insert(0, (\"undersampling\", RandomUnderSampler(sampling_strategy=\"auto\", random_state=seed)))\n",
        "    pipelines += [deepcopy(pipeline)]\n",
        "    pipeline.steps.insert(0, (\"oversampling\", RandomOverSampler(sampling_strategy=\"auto\", random_state=seed)))\n",
        "    pipelines += [deepcopy(pipeline)]\n",
        "    \n",
        "    out =  {}\n",
        "    for label, pipeline in zip(pipeline_labels, pipelines):\n",
        "        model_results = cross_validate(pipeline, X=X_train, y=y_train, cv=cv, scoring=scoring, return_estimator=True, return_train_score=True, fit_params=None)\n",
        "        # fetch training and validation scores on k folds\n",
        "        train_scores = pd.DataFrame({s: model_results[f\"test_{s}\"].mean() for s in scoring}, index=[model_label])\n",
        "        valid_scores = pd.DataFrame({s: model_results[f\"test_{s}\"].mean() for s in scoring}, index=[model_label])\n",
        "        print(f\"Running resampling strategy: {label}\")\n",
        "        out[label] = pd.concat({\"train\": train_scores, \"valid\": valid_scores}).round(2)\n",
        "    return pd.concat(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1677083247320
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running resampling strategy: SQ\n",
            "Running resampling strategy: undersample\n",
            "Running resampling strategy: oversample+undersample\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>fbeta_weighted</th>\n",
              "      <th>recall_weighted</th>\n",
              "      <th>precision_weighted</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>fbeta</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>average_precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">SQ</th>\n",
              "      <th>train</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valid</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.67</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">undersample</th>\n",
              "      <th>train</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valid</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">oversample+undersample</th>\n",
              "      <th>train</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valid</th>\n",
              "      <th>RF</th>\n",
              "      <td>0.70</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 balanced_accuracy  fbeta_weighted  \\\n",
              "SQ                     train RF               0.67            0.92   \n",
              "                       valid RF               0.67            0.92   \n",
              "undersample            train RF               0.80            0.80   \n",
              "                       valid RF               0.80            0.80   \n",
              "oversample+undersample train RF               0.70            0.91   \n",
              "                       valid RF               0.70            0.91   \n",
              "\n",
              "                                 recall_weighted  precision_weighted  roc_auc  \\\n",
              "SQ                     train RF             0.92                0.91     0.88   \n",
              "                       valid RF             0.92                0.91     0.88   \n",
              "undersample            train RF             0.80                0.90     0.88   \n",
              "                       valid RF             0.80                0.90     0.88   \n",
              "oversample+undersample train RF             0.91                0.90     0.88   \n",
              "                       valid RF             0.91                0.90     0.88   \n",
              "\n",
              "                                 accuracy  fbeta  recall  precision  \\\n",
              "SQ                     train RF      0.92   0.36    0.36       0.81   \n",
              "                       valid RF      0.92   0.36    0.36       0.81   \n",
              "undersample            train RF      0.80   0.80    0.81       0.34   \n",
              "                       valid RF      0.80   0.80    0.81       0.34   \n",
              "oversample+undersample train RF      0.91   0.43    0.43       0.67   \n",
              "                       valid RF      0.91   0.43    0.43       0.67   \n",
              "\n",
              "                                 average_precision  \n",
              "SQ                     train RF               0.62  \n",
              "                       valid RF               0.62  \n",
              "undersample            train RF               0.53  \n",
              "                       valid RF               0.53  \n",
              "oversample+undersample train RF               0.57  \n",
              "                       valid RF               0.57  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "compare_resampling_strategy(df, target_feature=PROXY_NOMINATION_TARGET)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "The results above suggest recall rate will benefit from training models with oversampling technique, which we use for the following. \n",
        "\n",
        "Note that other strategies to mitigate data imbalance are possible, for example:\n",
        "- using asymmetric cost function in model training objective (by setting higher class weights on minority classes);\n",
        "- ensembling diverse models on resampled data; or\n",
        "- treat the problem as anomaly detection if the minority class is very rare.\n",
        "\n",
        "## Run the supervised learning pipeline\n",
        "\n",
        "Specify the models you want to run. Depending on your input data and use case, consider:\n",
        "1. missingness in data and the ability of the model to handle it (e.g. LGBM, XGBoost)\n",
        "2. efficient or automatic encoding of categorical data (EBM)\n",
        "3. efficient interpretability with categorical feature support (EBM*, LGBM**)\n",
        "4. support from RAI dashboard (sklearn estimators only at the moment)\n",
        "\n",
        "\\* EBM support auto-encoding of categorical data type (e.g. \"object\", \"bool\", \"category\").  \n",
        "\n",
        "\\** shap.TreeExplainer supports only computation of shap values but not shap interaction values for LGBM trained on string features. As an alternative, it is also possible to interpret feature contributions from EBM (which fully supports categorical features) as shap interaction values where single feature contributions are the main effects and pairwise feature contributions are non-zero interaction effects.  \n",
        "\n",
        "The pipeline does the following:\n",
        "\n",
        "- plot label balance  \n",
        "- train a set of explanable predictive models with undersampling technique\n",
        "- evaluate model on validation and test performance metrics\n",
        "- generate global explanations\n",
        "- generate fairness metrics\n",
        "- can set global variable SHOW = True to generate diagnostic plots by data scientists "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1677083492531
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (35457, 190)  positive label pct 11.31%\n",
            "Validation/test data shape: (8865, 190)  positive label pct 11.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dummy takes 0.29 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Liblinear failed to converge, increase the number of iterations.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Logit takes 11.86 seconds\n",
            "Training RF takes 3.85 seconds\n",
            "[1]\tvalid_0's binary_logloss: 0.68905\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[2]\tvalid_0's binary_logloss: 0.685058\n",
            "[3]\tvalid_0's binary_logloss: 0.68112\n",
            "[4]\tvalid_0's binary_logloss: 0.677286\n",
            "[5]\tvalid_0's binary_logloss: 0.673526\n",
            "[6]\tvalid_0's binary_logloss: 0.669836\n",
            "[7]\tvalid_0's binary_logloss: 0.666211\n",
            "[8]\tvalid_0's binary_logloss: 0.662638\n",
            "[9]\tvalid_0's binary_logloss: 0.659165\n",
            "[10]\tvalid_0's binary_logloss: 0.655726\n",
            "[11]\tvalid_0's binary_logloss: 0.652369\n",
            "[12]\tvalid_0's binary_logloss: 0.649064\n",
            "[13]\tvalid_0's binary_logloss: 0.645867\n",
            "[14]\tvalid_0's binary_logloss: 0.642641\n",
            "[15]\tvalid_0's binary_logloss: 0.639489\n",
            "[16]\tvalid_0's binary_logloss: 0.636411\n",
            "[17]\tvalid_0's binary_logloss: 0.633353\n",
            "[18]\tvalid_0's binary_logloss: 0.630346\n",
            "[19]\tvalid_0's binary_logloss: 0.627409\n",
            "[20]\tvalid_0's binary_logloss: 0.624523\n",
            "[21]\tvalid_0's binary_logloss: 0.621684\n",
            "[22]\tvalid_0's binary_logloss: 0.618917\n",
            "[23]\tvalid_0's binary_logloss: 0.616201\n",
            "[24]\tvalid_0's binary_logloss: 0.613536\n",
            "[25]\tvalid_0's binary_logloss: 0.610893\n",
            "[26]\tvalid_0's binary_logloss: 0.608285\n",
            "[27]\tvalid_0's binary_logloss: 0.605791\n",
            "[28]\tvalid_0's binary_logloss: 0.603287\n",
            "[29]\tvalid_0's binary_logloss: 0.600846\n",
            "[30]\tvalid_0's binary_logloss: 0.598373\n",
            "[31]\tvalid_0's binary_logloss: 0.59599\n",
            "[32]\tvalid_0's binary_logloss: 0.593618\n",
            "[33]\tvalid_0's binary_logloss: 0.5913\n",
            "[34]\tvalid_0's binary_logloss: 0.589039\n",
            "[35]\tvalid_0's binary_logloss: 0.586761\n",
            "[36]\tvalid_0's binary_logloss: 0.584604\n",
            "[37]\tvalid_0's binary_logloss: 0.582411\n",
            "[38]\tvalid_0's binary_logloss: 0.580244\n",
            "[39]\tvalid_0's binary_logloss: 0.57811\n",
            "[40]\tvalid_0's binary_logloss: 0.576046\n",
            "[41]\tvalid_0's binary_logloss: 0.573994\n",
            "[42]\tvalid_0's binary_logloss: 0.57197\n",
            "[43]\tvalid_0's binary_logloss: 0.569973\n",
            "[44]\tvalid_0's binary_logloss: 0.568012\n",
            "[45]\tvalid_0's binary_logloss: 0.566096\n",
            "[46]\tvalid_0's binary_logloss: 0.564271\n",
            "[47]\tvalid_0's binary_logloss: 0.56239\n",
            "[48]\tvalid_0's binary_logloss: 0.560563\n",
            "[49]\tvalid_0's binary_logloss: 0.558755\n",
            "[50]\tvalid_0's binary_logloss: 0.557001\n",
            "[51]\tvalid_0's binary_logloss: 0.555221\n",
            "[52]\tvalid_0's binary_logloss: 0.553503\n",
            "[53]\tvalid_0's binary_logloss: 0.551792\n",
            "[54]\tvalid_0's binary_logloss: 0.550124\n",
            "[55]\tvalid_0's binary_logloss: 0.548473\n",
            "[56]\tvalid_0's binary_logloss: 0.546859\n",
            "[57]\tvalid_0's binary_logloss: 0.545246\n",
            "[58]\tvalid_0's binary_logloss: 0.543681\n",
            "[59]\tvalid_0's binary_logloss: 0.542171\n",
            "[60]\tvalid_0's binary_logloss: 0.540654\n",
            "[61]\tvalid_0's binary_logloss: 0.539151\n",
            "[62]\tvalid_0's binary_logloss: 0.537707\n",
            "[63]\tvalid_0's binary_logloss: 0.536251\n",
            "[64]\tvalid_0's binary_logloss: 0.534841\n",
            "[65]\tvalid_0's binary_logloss: 0.533424\n",
            "[66]\tvalid_0's binary_logloss: 0.532051\n",
            "[67]\tvalid_0's binary_logloss: 0.530718\n",
            "[68]\tvalid_0's binary_logloss: 0.529461\n",
            "[69]\tvalid_0's binary_logloss: 0.52813\n",
            "[70]\tvalid_0's binary_logloss: 0.526834\n",
            "[71]\tvalid_0's binary_logloss: 0.525513\n",
            "[72]\tvalid_0's binary_logloss: 0.524252\n",
            "[73]\tvalid_0's binary_logloss: 0.523015\n",
            "[74]\tvalid_0's binary_logloss: 0.521798\n",
            "[75]\tvalid_0's binary_logloss: 0.5206\n",
            "[76]\tvalid_0's binary_logloss: 0.519405\n",
            "[77]\tvalid_0's binary_logloss: 0.51824\n",
            "[78]\tvalid_0's binary_logloss: 0.517103\n",
            "[79]\tvalid_0's binary_logloss: 0.515983\n",
            "[80]\tvalid_0's binary_logloss: 0.514895\n",
            "[81]\tvalid_0's binary_logloss: 0.513781\n",
            "[82]\tvalid_0's binary_logloss: 0.512738\n",
            "[83]\tvalid_0's binary_logloss: 0.51168\n",
            "[84]\tvalid_0's binary_logloss: 0.510632\n",
            "[85]\tvalid_0's binary_logloss: 0.509612\n",
            "[86]\tvalid_0's binary_logloss: 0.508581\n",
            "[87]\tvalid_0's binary_logloss: 0.507582\n",
            "[88]\tvalid_0's binary_logloss: 0.506632\n",
            "[89]\tvalid_0's binary_logloss: 0.505596\n",
            "[90]\tvalid_0's binary_logloss: 0.504622\n",
            "[91]\tvalid_0's binary_logloss: 0.50363\n",
            "[92]\tvalid_0's binary_logloss: 0.502589\n",
            "[93]\tvalid_0's binary_logloss: 0.501633\n",
            "[94]\tvalid_0's binary_logloss: 0.500746\n",
            "[95]\tvalid_0's binary_logloss: 0.499787\n",
            "[96]\tvalid_0's binary_logloss: 0.49886\n",
            "[97]\tvalid_0's binary_logloss: 0.497988\n",
            "[98]\tvalid_0's binary_logloss: 0.497035\n",
            "[99]\tvalid_0's binary_logloss: 0.49615\n",
            "[100]\tvalid_0's binary_logloss: 0.495317\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.495317\n",
            "[1]\tvalid_0's binary_logloss: 0.689133\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[2]\tvalid_0's binary_logloss: 0.685187\n",
            "[3]\tvalid_0's binary_logloss: 0.68132\n",
            "[4]\tvalid_0's binary_logloss: 0.677516\n",
            "[5]\tvalid_0's binary_logloss: 0.673808\n",
            "[6]\tvalid_0's binary_logloss: 0.670167\n",
            "[7]\tvalid_0's binary_logloss: 0.666594\n",
            "[8]\tvalid_0's binary_logloss: 0.663096\n",
            "[9]\tvalid_0's binary_logloss: 0.659659\n",
            "[10]\tvalid_0's binary_logloss: 0.656305\n",
            "[11]\tvalid_0's binary_logloss: 0.653028\n",
            "[12]\tvalid_0's binary_logloss: 0.649785\n",
            "[13]\tvalid_0's binary_logloss: 0.646617\n",
            "[14]\tvalid_0's binary_logloss: 0.643494\n",
            "[15]\tvalid_0's binary_logloss: 0.640451\n",
            "[16]\tvalid_0's binary_logloss: 0.637438\n",
            "[17]\tvalid_0's binary_logloss: 0.63448\n",
            "[18]\tvalid_0's binary_logloss: 0.631586\n",
            "[19]\tvalid_0's binary_logloss: 0.628751\n",
            "[20]\tvalid_0's binary_logloss: 0.625957\n",
            "[21]\tvalid_0's binary_logloss: 0.623212\n",
            "[22]\tvalid_0's binary_logloss: 0.620519\n",
            "[23]\tvalid_0's binary_logloss: 0.617874\n",
            "[24]\tvalid_0's binary_logloss: 0.615307\n",
            "[25]\tvalid_0's binary_logloss: 0.612735\n",
            "[26]\tvalid_0's binary_logloss: 0.610199\n",
            "[27]\tvalid_0's binary_logloss: 0.607725\n",
            "[28]\tvalid_0's binary_logloss: 0.605306\n",
            "[29]\tvalid_0's binary_logloss: 0.602913\n",
            "[30]\tvalid_0's binary_logloss: 0.600545\n",
            "[31]\tvalid_0's binary_logloss: 0.59823\n",
            "[32]\tvalid_0's binary_logloss: 0.595956\n",
            "[33]\tvalid_0's binary_logloss: 0.593704\n",
            "[34]\tvalid_0's binary_logloss: 0.591475\n",
            "[35]\tvalid_0's binary_logloss: 0.58931\n",
            "[36]\tvalid_0's binary_logloss: 0.587156\n",
            "[37]\tvalid_0's binary_logloss: 0.584994\n",
            "[38]\tvalid_0's binary_logloss: 0.582897\n",
            "[39]\tvalid_0's binary_logloss: 0.58088\n",
            "[40]\tvalid_0's binary_logloss: 0.578878\n",
            "[41]\tvalid_0's binary_logloss: 0.576882\n",
            "[42]\tvalid_0's binary_logloss: 0.574924\n",
            "[43]\tvalid_0's binary_logloss: 0.573076\n",
            "[44]\tvalid_0's binary_logloss: 0.571134\n",
            "[45]\tvalid_0's binary_logloss: 0.569272\n",
            "[46]\tvalid_0's binary_logloss: 0.567487\n",
            "[47]\tvalid_0's binary_logloss: 0.565661\n",
            "[48]\tvalid_0's binary_logloss: 0.563917\n",
            "[49]\tvalid_0's binary_logloss: 0.562183\n",
            "[50]\tvalid_0's binary_logloss: 0.560357\n",
            "[51]\tvalid_0's binary_logloss: 0.558605\n",
            "[52]\tvalid_0's binary_logloss: 0.556826\n",
            "[53]\tvalid_0's binary_logloss: 0.555104\n",
            "[54]\tvalid_0's binary_logloss: 0.553453\n",
            "[55]\tvalid_0's binary_logloss: 0.551796\n",
            "[56]\tvalid_0's binary_logloss: 0.550143\n",
            "[57]\tvalid_0's binary_logloss: 0.548576\n",
            "[58]\tvalid_0's binary_logloss: 0.546994\n",
            "[59]\tvalid_0's binary_logloss: 0.545402\n",
            "[60]\tvalid_0's binary_logloss: 0.543886\n",
            "[61]\tvalid_0's binary_logloss: 0.542387\n",
            "[62]\tvalid_0's binary_logloss: 0.540918\n",
            "[63]\tvalid_0's binary_logloss: 0.539406\n",
            "[64]\tvalid_0's binary_logloss: 0.537954\n",
            "[65]\tvalid_0's binary_logloss: 0.536536\n",
            "[66]\tvalid_0's binary_logloss: 0.535103\n",
            "[67]\tvalid_0's binary_logloss: 0.533717\n",
            "[68]\tvalid_0's binary_logloss: 0.532347\n",
            "[69]\tvalid_0's binary_logloss: 0.530938\n",
            "[70]\tvalid_0's binary_logloss: 0.529633\n",
            "[71]\tvalid_0's binary_logloss: 0.528274\n",
            "[72]\tvalid_0's binary_logloss: 0.527019\n",
            "[73]\tvalid_0's binary_logloss: 0.525745\n",
            "[74]\tvalid_0's binary_logloss: 0.52449\n",
            "[75]\tvalid_0's binary_logloss: 0.523292\n",
            "[76]\tvalid_0's binary_logloss: 0.522103\n",
            "[77]\tvalid_0's binary_logloss: 0.520939\n",
            "[78]\tvalid_0's binary_logloss: 0.51979\n",
            "[79]\tvalid_0's binary_logloss: 0.518581\n",
            "[80]\tvalid_0's binary_logloss: 0.517502\n",
            "[81]\tvalid_0's binary_logloss: 0.51642\n",
            "[82]\tvalid_0's binary_logloss: 0.515355\n",
            "[83]\tvalid_0's binary_logloss: 0.51438\n",
            "[84]\tvalid_0's binary_logloss: 0.513231\n",
            "[85]\tvalid_0's binary_logloss: 0.512226\n",
            "[86]\tvalid_0's binary_logloss: 0.511239\n",
            "[87]\tvalid_0's binary_logloss: 0.510139\n",
            "[88]\tvalid_0's binary_logloss: 0.509184\n",
            "[89]\tvalid_0's binary_logloss: 0.508138\n",
            "[90]\tvalid_0's binary_logloss: 0.507254\n",
            "[91]\tvalid_0's binary_logloss: 0.506188\n",
            "[92]\tvalid_0's binary_logloss: 0.505228\n",
            "[93]\tvalid_0's binary_logloss: 0.504291\n",
            "[94]\tvalid_0's binary_logloss: 0.503345\n",
            "[95]\tvalid_0's binary_logloss: 0.502385\n",
            "[96]\tvalid_0's binary_logloss: 0.50148\n",
            "[97]\tvalid_0's binary_logloss: 0.500638\n",
            "[98]\tvalid_0's binary_logloss: 0.499697\n",
            "[99]\tvalid_0's binary_logloss: 0.498783\n",
            "[100]\tvalid_0's binary_logloss: 0.49798\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.49798\n",
            "[1]\tvalid_0's binary_logloss: 0.689285\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[2]\tvalid_0's binary_logloss: 0.685503\n",
            "[3]\tvalid_0's binary_logloss: 0.681802\n",
            "[4]\tvalid_0's binary_logloss: 0.678138\n",
            "[5]\tvalid_0's binary_logloss: 0.674551\n",
            "[6]\tvalid_0's binary_logloss: 0.671028\n",
            "[7]\tvalid_0's binary_logloss: 0.66754\n",
            "[8]\tvalid_0's binary_logloss: 0.664135\n",
            "[9]\tvalid_0's binary_logloss: 0.660809\n",
            "[10]\tvalid_0's binary_logloss: 0.657564\n",
            "[11]\tvalid_0's binary_logloss: 0.654336\n",
            "[12]\tvalid_0's binary_logloss: 0.651164\n",
            "[13]\tvalid_0's binary_logloss: 0.648101\n",
            "[14]\tvalid_0's binary_logloss: 0.645089\n",
            "[15]\tvalid_0's binary_logloss: 0.642122\n",
            "[16]\tvalid_0's binary_logloss: 0.639175\n",
            "[17]\tvalid_0's binary_logloss: 0.636304\n",
            "[18]\tvalid_0's binary_logloss: 0.633464\n",
            "[19]\tvalid_0's binary_logloss: 0.630667\n",
            "[20]\tvalid_0's binary_logloss: 0.627897\n",
            "[21]\tvalid_0's binary_logloss: 0.625069\n",
            "[22]\tvalid_0's binary_logloss: 0.622399\n",
            "[23]\tvalid_0's binary_logloss: 0.619696\n",
            "[24]\tvalid_0's binary_logloss: 0.617122\n",
            "[25]\tvalid_0's binary_logloss: 0.614588\n",
            "[26]\tvalid_0's binary_logloss: 0.612007\n",
            "[27]\tvalid_0's binary_logloss: 0.609534\n",
            "[28]\tvalid_0's binary_logloss: 0.607094\n",
            "[29]\tvalid_0's binary_logloss: 0.604708\n",
            "[30]\tvalid_0's binary_logloss: 0.602386\n",
            "[31]\tvalid_0's binary_logloss: 0.600103\n",
            "[32]\tvalid_0's binary_logloss: 0.59778\n",
            "[33]\tvalid_0's binary_logloss: 0.595561\n",
            "[34]\tvalid_0's binary_logloss: 0.593346\n",
            "[35]\tvalid_0's binary_logloss: 0.591205\n",
            "[36]\tvalid_0's binary_logloss: 0.589065\n",
            "[37]\tvalid_0's binary_logloss: 0.586962\n",
            "[38]\tvalid_0's binary_logloss: 0.584917\n",
            "[39]\tvalid_0's binary_logloss: 0.582959\n",
            "[40]\tvalid_0's binary_logloss: 0.580932\n",
            "[41]\tvalid_0's binary_logloss: 0.579028\n",
            "[42]\tvalid_0's binary_logloss: 0.577097\n",
            "[43]\tvalid_0's binary_logloss: 0.575218\n",
            "[44]\tvalid_0's binary_logloss: 0.573409\n",
            "[45]\tvalid_0's binary_logloss: 0.571501\n",
            "[46]\tvalid_0's binary_logloss: 0.56977\n",
            "[47]\tvalid_0's binary_logloss: 0.567927\n",
            "[48]\tvalid_0's binary_logloss: 0.566199\n",
            "[49]\tvalid_0's binary_logloss: 0.564534\n",
            "[50]\tvalid_0's binary_logloss: 0.562836\n",
            "[51]\tvalid_0's binary_logloss: 0.561239\n",
            "[52]\tvalid_0's binary_logloss: 0.559663\n",
            "[53]\tvalid_0's binary_logloss: 0.558023\n",
            "[54]\tvalid_0's binary_logloss: 0.556511\n",
            "[55]\tvalid_0's binary_logloss: 0.554856\n",
            "[56]\tvalid_0's binary_logloss: 0.553371\n",
            "[57]\tvalid_0's binary_logloss: 0.551903\n",
            "[58]\tvalid_0's binary_logloss: 0.550428\n",
            "[59]\tvalid_0's binary_logloss: 0.54899\n",
            "[60]\tvalid_0's binary_logloss: 0.547528\n",
            "[61]\tvalid_0's binary_logloss: 0.54617\n",
            "[62]\tvalid_0's binary_logloss: 0.544828\n",
            "[63]\tvalid_0's binary_logloss: 0.543379\n",
            "[64]\tvalid_0's binary_logloss: 0.542065\n",
            "[65]\tvalid_0's binary_logloss: 0.540771\n",
            "[66]\tvalid_0's binary_logloss: 0.539457\n",
            "[67]\tvalid_0's binary_logloss: 0.538132\n",
            "[68]\tvalid_0's binary_logloss: 0.536897\n",
            "[69]\tvalid_0's binary_logloss: 0.535608\n",
            "[70]\tvalid_0's binary_logloss: 0.53437\n",
            "[71]\tvalid_0's binary_logloss: 0.533069\n",
            "[72]\tvalid_0's binary_logloss: 0.531811\n",
            "[73]\tvalid_0's binary_logloss: 0.530623\n",
            "[74]\tvalid_0's binary_logloss: 0.52949\n",
            "[75]\tvalid_0's binary_logloss: 0.528287\n",
            "[76]\tvalid_0's binary_logloss: 0.527117\n",
            "[77]\tvalid_0's binary_logloss: 0.525981\n",
            "[78]\tvalid_0's binary_logloss: 0.52486\n",
            "[79]\tvalid_0's binary_logloss: 0.523809\n",
            "[80]\tvalid_0's binary_logloss: 0.522636\n",
            "[81]\tvalid_0's binary_logloss: 0.521564\n",
            "[82]\tvalid_0's binary_logloss: 0.52064\n",
            "[83]\tvalid_0's binary_logloss: 0.519609\n",
            "[84]\tvalid_0's binary_logloss: 0.518595\n",
            "[85]\tvalid_0's binary_logloss: 0.517513\n",
            "[86]\tvalid_0's binary_logloss: 0.516526\n",
            "[87]\tvalid_0's binary_logloss: 0.515591\n",
            "[88]\tvalid_0's binary_logloss: 0.514654\n",
            "[89]\tvalid_0's binary_logloss: 0.513725\n",
            "[90]\tvalid_0's binary_logloss: 0.512691\n",
            "[91]\tvalid_0's binary_logloss: 0.511796\n",
            "[92]\tvalid_0's binary_logloss: 0.51093\n",
            "[93]\tvalid_0's binary_logloss: 0.510024\n",
            "[94]\tvalid_0's binary_logloss: 0.509059\n",
            "[95]\tvalid_0's binary_logloss: 0.508168\n",
            "[96]\tvalid_0's binary_logloss: 0.507331\n",
            "[97]\tvalid_0's binary_logloss: 0.506439\n",
            "[98]\tvalid_0's binary_logloss: 0.50566\n",
            "[99]\tvalid_0's binary_logloss: 0.504826\n",
            "[100]\tvalid_0's binary_logloss: 0.504004\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\tvalid_0's binary_logloss: 0.504004\n",
            "Training LGBM takes 1.46 seconds\n",
            "Training EBM takes 42.87 seconds\n",
            "Generating shap values for RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1). This may take a while ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There may exist memory issue for algorithm v2. Switched to algorithm v1.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time spent on explaining RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1): 25.97 seconds\n",
            "Generating shap values for LGBMClassifier(learning_rate=0.01, random_state=1, verbose=-1). This may take a while ...\n",
            "Time spent on explaining LGBMClassifier(learning_rate=0.01, random_state=1, verbose=-1): 1.72 seconds\n",
            "there is floating point error in converting EBM contr to shap interaction values!\n",
            "RF local accuracy may have precision issues!\n",
            "LGBM local accuracy may have precision issues!\n",
            "EBM local accuracy may have precision issues!\n",
            "supervised train\n",
            "Dummy data has 44322 rows with 5054 class 1 (11.40%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "supervised test\n",
            "Dummy data has 11081 rows with 1326 class 1 (11.97%)\n",
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "Error occurred in computing fairness parity metrics. This might be normal if this is a dummy classifier predicting only one class. Skipping ...\n",
            "float division by zero\n",
            "Evaluating Dummy on accuracy and fairness takes 1.38 seconds\n",
            "supervised train\n",
            "Logit data has 44322 rows with 5054 class 1 (11.40%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervised test\n",
            "Logit data has 11081 rows with 1326 class 1 (11.97%)\n",
            "Evaluating Logit on accuracy and fairness takes 1.37 seconds\n",
            "supervised train\n",
            "RF data has 44322 rows with 5054 class 1 (11.40%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervised test\n",
            "RF data has 11081 rows with 1326 class 1 (11.97%)\n",
            "Evaluating RF on accuracy and fairness takes 1.36 seconds\n",
            "supervised train\n",
            "LGBM data has 44322 rows with 5054 class 1 (11.40%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervised test\n",
            "LGBM data has 11081 rows with 1326 class 1 (11.97%)\n",
            "Evaluating LGBM on accuracy and fairness takes 1.38 seconds\n",
            "supervised train\n",
            "EBM data has 44322 rows with 5054 class 1 (11.40%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervised test\n",
            "EBM data has 11081 rows with 1326 class 1 (11.97%)\n",
            "Evaluating EBM on accuracy and fairness takes 1.37 seconds\n",
            "Generating shap values for RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1). This may take a while ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There may exist memory issue for algorithm v2. Switched to algorithm v1.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time spent on explaining RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=1): 25.93 seconds\n",
            "Generating shap values for LGBMClassifier(learning_rate=0.01, random_state=1, verbose=-1). This may take a while ...\n",
            "Time spent on explaining LGBMClassifier(learning_rate=0.01, random_state=1, verbose=-1): 2.15 seconds\n",
            "there is floating point error in converting EBM contr to shap interaction values!\n",
            "RF local accuracy may have precision issues!\n",
            "LGBM local accuracy may have precision issues!\n",
            "EBM local accuracy may have precision issues!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# specify seed and turn on CPU parallelism\n",
        "fixed_args = dict(random_state=SEED, n_jobs=-1) \n",
        "\n",
        "# specify model(s) to run; to run RAI dashboard, only sklearn models (e.g. Logit and RF below) are currently supported \n",
        "model_dict = {\n",
        "    \"Dummy\": DummyClassifier(strategy=\"most_frequent\"), # set a baseline for imbalanced dataset\n",
        "    \"Logit\": skLogit(penalty=\"l1\", solver=\"liblinear\", random_state=SEED),  # requires one-hot encoding for categorical features\n",
        "    \"RF\": RandomForestClassifier(oob_score=True, **fixed_args), #  requires one-hot encoding for categorical features\n",
        "    \"LGBM\": LGBMClassifier(learning_rate=0.01, verbose=-1, **fixed_args),   \n",
        "    \"EBM\": ExplainableBoostingClassifier(**fixed_args),\n",
        "}\n",
        "proxy_supervised_nomination = run_supervised_learning_on_nomination(df, model_dict=model_dict, use_proxy_label=True, seed=SEED)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## How to extract supervised learning pipeline outputs\n",
        "1. model: a ML model object with sklearn-style API  \n",
        "2. predicted_data: a pandas dataframe with features, labels, predicted labels, pseudonymized student ids, and a column \"dataset\" with values \"train\" or \"test\" indicating dataset type\n",
        "3. accuracy_scores: a pandas dataframe with accuracy scores on training and test dataset\n",
        "4. fairness_scores: a pandas dataframe with fairness scores on training and test dataset\n",
        "5. feature_importance: a pandas dataframe with local feature importance (the same shape as model input) for each data row; and the features may be organized in a hierarchy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1677083492741
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# post-process model outputs\n",
        "# define functions to add dummy time and school info for downstream PowerBI dashboard consumption \n",
        "def add_dummy_school(df, n_schools=10, school_feature=SCHOOL_ID):\n",
        "    if school_feature not in df:\n",
        "        dummy_school_values = np.random.choice(n_schools, size=df.shape[0], replace=True)\n",
        "        df[school_feature] = dummy_school_values\n",
        "    return df\n",
        "\n",
        "def add_dummy_time(df, start, end, freq):\n",
        "    # create the date range for the specified frequency \n",
        "    dummy_time_range = pd.date_range(start=start, end=end, freq=freq)\n",
        "    # assign to each row a random time stamp\n",
        "    dummy_time_stamps = DEFAULT_RNG.choice(dummy_time_range, replace=True, size=df.shape[0])\n",
        "    df[TIME_STAMP] = pd.to_datetime(dummy_time_stamps)\n",
        "    return df\n",
        "\n",
        "# variables defined\n",
        "model_label = \"RF\"\n",
        "train_features = FEATURE_NAMES\n",
        "school_feature = SCHOOL_ID\n",
        "use_proxy_label = True  # add proxy labels or not\n",
        "target_feature = PROXY_NOMINATION_TARGET if use_proxy_label else NOMINATION_TARGET\n",
        "predicted_feature = f\"{target_feature}{model_label}Proba\"\n",
        "\n",
        "# predicted_data a pandas dataframe with features, labels, predicted labels, pseudonymized student ids, and a column \"dataset\" with values \"train\" or \"test\" indicating dataset type\n",
        "predicted_data = proxy_supervised_nomination[\"predicted_data\"].copy()\n",
        "\n",
        "\n",
        "# also add dummy school and time stamp info\n",
        "predicted_data = add_dummy_school(predicted_data, n_schools=10, school_feature=SCHOOL_ID)\n",
        "predicted_data = add_dummy_time(predicted_data, start=\"2018-01-01\", end=\"2023-01-01\", freq=\"Q\")  # \"Q\" for quarterly frequency\n",
        "\n",
        "#  get training and test dataset (indexed by student id) \n",
        "indexed_data = predicted_data.set_index(STUDENT_ID)\n",
        "train_data = indexed_data[indexed_data[\"dataset\"] == \"train\"]\n",
        "test_data = indexed_data[indexed_data[\"dataset\"] == \"test\"]\n",
        "\n",
        "# get the dataframe with all columns\n",
        "available_columns = [STUDENT_ID, target_feature, predicted_feature, \"dataset\", SCHOOL_ID, TIME_STAMP] + train_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Model outputs (pandas dataframes) for PowerBI consumptions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1677083494032
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# PowerBI dashboard 1\n",
        "# for pie chart target feature distribution (binary variable)\n",
        "target_dist = predicted_data[target_feature].value_counts(normalize=True).rename(\"Percentage\").rename_axis(target_feature)\n",
        "# for bar chart with school break-down\n",
        "target_dist_by_school = predicted_data.groupby(SCHOOL_ID)[target_feature].mean()\n",
        "# for time-series chart\n",
        "quarterly_target_mean = predicted_data.groupby([SCHOOL_ID, TIME_STAMP])[target_feature].mean()\n",
        "\n",
        "# PowerBI dashboard 2 \n",
        "# feature importance dataframes for a given model\n",
        "feature_importance = proxy_supervised_nomination[\"feature_importance\"].copy()\n",
        "feature_importance = feature_importance.loc[pd.IndexSlice[model_label, :], :]\n",
        "feature_importance.index.names = [\"Model\", STUDENT_ID]\n",
        "feature_importance_pivot = feature_importance.unstack(level=0)\n",
        "# add school index\n",
        "school_index = feature_importance_pivot.index.map(predicted_data.set_index(STUDENT_ID)[SCHOOL_ID].to_dict())\n",
        "school_index.name = SCHOOL_ID\n",
        "feature_importance_pivot.set_index(school_index, append=True, inplace=True)\n",
        "\n",
        "# find the top k feature to display\n",
        "top_k_features = 4 \n",
        "# for the student records where top k features are shown: user can query individual student's ranked features \n",
        "feature_importance_magnitude = feature_importance_pivot.stack([0, 1, 2]).rename('Magnitude').abs().reset_index()\n",
        "top_k_feature_idx = feature_importance_magnitude.groupby([SCHOOL_ID, STUDENT_ID, \"Model\"])[\"Magnitude\"].nlargest(top_k_features).index.get_level_values(-1)\n",
        "student_feature_importance = feature_importance_magnitude.loc[top_k_feature_idx]\n",
        "\n",
        "# for bar chart with average magnitude of the top k important feature contributions\n",
        "individual_feature_importance =  feature_importance_pivot.unstack(level=-1).apply(lambda x: x.abs().mean(), axis=0).rename(\"AverageMagnitude\")\n",
        "# (additional) for bar chart with avearge magnitude of the contribution from each category of features\n",
        "categorical_feature_importance = feature_importance_pivot.unstack(level=-1).groupby(axis=1, level=[0, -2, -1]).sum().apply(lambda x: x.abs().mean(), axis=0).rename(\"AverageMagnitude\")\n",
        "\n",
        "# PowerBI dashboard 3\n",
        "# for bar chart with accuracy scores for a given model\n",
        "accuracy_scores = proxy_supervised_nomination[\"accuracy_scores\"].copy()\n",
        "accuracy_scores = accuracy_scores.loc[pd.IndexSlice[model_label, :], :]\n",
        "accuracy_scores.index.names = [\"Model\", \"Dataset\"]\n",
        "# for table showing fairness summary for a given model\n",
        "fairness_scores = proxy_supervised_nomination[\"fairness_scores\"].copy()\n",
        "fairness_scores = fairness_scores.loc[pd.IndexSlice[model_label, :, :, :], :]\n",
        "fairness_scores.index.names = [\"Model\", \"Dataset\", \"SensitiveFeature\", \"ParityMetric\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1677083502286
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving table dataset-PBI_target_dist_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/526852c1-98ee-4894-9605-9f5b168c329e/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_target_dist_by_school_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/b0ca37fc-a06e-472d-b948-7ea71a36cfcd/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_quarterly_target_mean_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/885a76b5-5bda-4b7f-8b99-9aabd7a5a9aa/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_student_feature_importance_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/72456036-24db-447f-85a0-d23c67c2669e/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_individual_feature_importance_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/9ac106b6-41e6-4260-9a63-16d341cfab03/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_categorical_feature_importance_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/6858294f-b177-490e-9d45-461ef1bc57c1/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_accuracy_scores_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/c8a0f207-acd5-404f-9618-5a39bc30bb8d/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "saving table dataset-PBI_fairness_scores_numeric ...\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/455073ee-0050-4b69-8c18-df380c62f6b9/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pbi_tables = [target_dist, target_dist_by_school, quarterly_target_mean, student_feature_importance, individual_feature_importance, categorical_feature_importance, accuracy_scores, fairness_scores]\n",
        "pbi_table_names = [\"target_dist\", \"target_dist_by_school\", \"quarterly_target_mean\", \"student_feature_importance\", \"individual_feature_importance\", \"categorical_feature_importance\", \"accuracy_scores\", \"fairness_scores\"]\n",
        "\n",
        "# register PowerBI data on AML\n",
        "config = toml.load('config.txt')\n",
        "datastore_name = config[\"datastore_name\"]\n",
        "\n",
        "workspace = Workspace.from_config()\n",
        "datastore = Datastore.get(workspace, datastore_name)\n",
        "\n",
        "for table_name, table in zip(pbi_table_names, pbi_tables):\n",
        "    table_name += \"_numeric\"\n",
        "    table = table.reset_index()\n",
        "    print(f\"saving table dataset-PBI_{table_name} ...\")\n",
        "    Dataset.Tabular.register_pandas_dataframe(table, datastore, f\"dataset-PBI_{table_name}\", show_progress=True)\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Model outputs for RAI dashboards\n",
        "1. datasets: must provide separate train dataset for training and test dataset for evaluation; they must only contain label and feature columns and nothing else \n",
        "2. model: a native sklearn estimator object (LGBM & EBM are not yet supported)\n",
        "\n",
        "We need to register these artifacts and upload them onto AML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1677083524636
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/371cea8e-fc6e-4ee0-a1f1-195c802f2504/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/2e7023a7-44ad-40e7-a330-d5f479626c53/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n",
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/c8a20a09-901d-4a19-87d6-1602711e22a4/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'ProxyNominationRF' already exists. Creating a new version of this model...\n",
            "2023/03/10 16:22:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ProxyNominationRF, version 32\n",
            "Created version '32' of model 'ProxyNominationRF'.\n"
          ]
        }
      ],
      "source": [
        "# training and test data for RAI dashboards\n",
        "rai_train_data = train_data[[target_feature]+FEATURE_NAMES].copy()\n",
        "rai_test_data = test_data[[target_feature]+FEATURE_NAMES].copy()\n",
        "# rai_test_data has a maximum row limit to 5000 and a large dataframe makes computation generally very slow for full functionality \n",
        "# so a small sample is provided here for illustration purpose\n",
        "test_sample_limit = 1000\n",
        "rai_test_data_sample = rai_test_data.copy()\n",
        "if rai_test_data.shape[0] > test_sample_limit: \n",
        "    rai_test_data_sample = rai_test_data.sample(test_sample_limit, random_state=SEED).copy()\n",
        "\n",
        "# model_labels has options: RF, LGBM, EBM, Logit, and Dummy. You may train these models; \n",
        "# however, RAI dashboard currently only supports native sklearn estimators\n",
        "model_label = \"RF\" \n",
        "\n",
        "# pipeline is a sklearn-like Pipeline object with a .predict method\n",
        "pipeline = proxy_supervised_nomination[\"nomination_results\"][\"cv_results\"][model_label][\"estimator\"][0]\n",
        "# model is the estimator object in the last step of the sklearn pipeline \n",
        "model = pipeline.steps[-1][1]\n",
        "\n",
        "\n",
        "# register PowerBI data on AML\n",
        "config = toml.load('config.txt')\n",
        "datastore_name = config[\"datastore_name\"]\n",
        "\n",
        "workspace = Workspace.from_config()\n",
        "datastore = Datastore.get(workspace, datastore_name)\n",
        "\n",
        "# register RAI data on AML\n",
        "Dataset.Tabular.register_pandas_dataframe(rai_train_data, datastore, \"dataset-RAI_MainData_train_numeric\", show_progress=True)\n",
        "Dataset.Tabular.register_pandas_dataframe(rai_test_data, datastore, \"dataset-RAI_MainData_test_numeric\", show_progress=True)\n",
        "Dataset.Tabular.register_pandas_dataframe(rai_test_data_sample, datastore, \"dataset-RAI_MainData_test_sample_numeric\", show_progress=True)\n",
        "\n",
        "# register model onto AML\n",
        "with mlflow.start_run() as run:\n",
        "    artifact_name = f\"ProxyNomination{model_label}\"\n",
        "    mlflow.sklearn.log_model(sk_model=model, artifact_path=artifact_name)\n",
        "    model_uri = f\"runs:/{run.info.run_id}/{artifact_name}\"\n",
        "    mlflow.register_model(model_uri=model_uri, name=artifact_name)\n",
        " "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mitigate model fairness\n",
        "\n",
        "An \"unmitigated\" ML model means that the model has been optimized with respect to particular fairness metrics. You can use fairlearn to compare between mitigated and un-mitigated models, and decide what model to use. AzureML studio supports fairness dashboard hosted in a notebook for your convenience.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1677083524880
        }
      },
      "outputs": [],
      "source": [
        "# define variables used:\n",
        "# sensitive_features could be a string or a list (single or multi-dimensional). \n",
        "# Note multidimensional constraint may result in fewer or even no pareto-optimal solutions and much longer computation time \n",
        "sensitive_features = [\"EconomicDisadvantageSTAS_Y\", \"Disability_Y\"]\n",
        "X_train, y_train, sensitive_features_train = train_data[FEATURE_NAMES], train_data[target_feature], train_data[sensitive_features]\n",
        "X_test, y_test, sensitive_features_test = test_data[FEATURE_NAMES], test_data[target_feature], test_data[sensitive_features]\n",
        "\n",
        "# Fairlearn is not yet fully compatible with Pipelines, so we have to pass the model estimator only\n",
        "unmitigated_predictor = pipeline.steps[-1][1] \n",
        "\n",
        "# using undersampling in the pipeline also means we need to apply this preprocess to training data \n",
        "# but not the test data since we wouldn\"t know the real label distribution out of sample \n",
        "preprocessor = pipeline_with_sampler(steps=pipeline.steps[:-1])\n",
        "X_train_prep, y_train_prep = preprocessor.fit_resample(X_train, y_train)\n",
        "sensitive_features_train_prep = X_train_prep[sensitive_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1677083526521
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "selection rate            0.271275\n",
            "recall                    0.801659\n",
            "fbeta_score               0.791728\n",
            "true positive rate        0.801659\n",
            "count                 11081.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>selection rate</th>\n",
              "      <th>recall</th>\n",
              "      <th>fbeta_score</th>\n",
              "      <th>true positive rate</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EconomicDisadvantageSTAS_Y</th>\n",
              "      <th>Disability_Y</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>0.058355</td>\n",
              "      <td>0.596026</td>\n",
              "      <td>0.594351</td>\n",
              "      <td>0.596026</td>\n",
              "      <td>6649.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.391379</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.758014</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>580.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>0.538336</td>\n",
              "      <td>0.822848</td>\n",
              "      <td>0.809068</td>\n",
              "      <td>0.822848</td>\n",
              "      <td>3052.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.960486</td>\n",
              "      <td>0.948526</td>\n",
              "      <td>0.960486</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         selection rate    recall  \\\n",
              "EconomicDisadvantageSTAS_Y Disability_Y                             \n",
              "0                          0                   0.058355  0.596026   \n",
              "                           1                   0.391379  0.769231   \n",
              "1                          0                   0.538336  0.822848   \n",
              "                           1                   0.935000  0.960486   \n",
              "\n",
              "                                         fbeta_score  true positive rate  \\\n",
              "EconomicDisadvantageSTAS_Y Disability_Y                                    \n",
              "0                          0                0.594351            0.596026   \n",
              "                           1                0.758014            0.769231   \n",
              "1                          0                0.809068            0.822848   \n",
              "                           1                0.948526            0.960486   \n",
              "\n",
              "                                          count  \n",
              "EconomicDisadvantageSTAS_Y Disability_Y          \n",
              "0                          0             6649.0  \n",
              "                           1              580.0  \n",
              "1                          0             3052.0  \n",
              "                           1              800.0  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We can start to assess the predictors fairness using the MetricFrame:\n",
        "metric_frame = MetricFrame(\n",
        "    metrics=fairness_metrics,\n",
        "    sensitive_features=sensitive_features_test,\n",
        "    y_true=y_test,\n",
        "    y_pred=unmitigated_predictor.predict(X_test),\n",
        ")\n",
        "metric_frame.by_group.plot.bar(\n",
        "    subplots=True,\n",
        "    layout=[len(fairness_metrics.keys()), 1],\n",
        "    legend=False,\n",
        "    figsize=[5, len(fairness_metrics.keys()) * 2],\n",
        "    title=\"Accuracy and selection rate by group\",\n",
        ")\n",
        "print(metric_frame.overall)\n",
        "metric_frame.by_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1677083996917
        }
      },
      "outputs": [],
      "source": [
        "fairness_grid_size = 500\n",
        "# train additional models to attempt to migiate fairness issues\n",
        "sweep = GridSearch(model,\n",
        "                   constraints=DemographicParity(),\n",
        "                   grid_size=fairness_grid_size)\n",
        "\n",
        "# Fairlearns provide fit() and predict() methods, so they behave in a similar manner to other ML packages in Python. \n",
        "# We do however have to specify two extra arguments to fit() - the column of protected attribute labels, and also the number of predictors to generate in our sweep.\n",
        "#After fit() completes, we extract the full set of predictors from the GridSearch object.\n",
        "\n",
        "sweep.fit(X_train_prep, y_train_prep,\n",
        "          sensitive_features=sensitive_features_train_prep)\n",
        "\n",
        "predictors = sweep.predictors_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1677084197445
        }
      },
      "outputs": [],
      "source": [
        "# We could plot performance and fairness metrics of these predictors now. \n",
        "# However, the plot would be somewhat confusing due to the large number of models. \n",
        "# In this case, we are going to remove the predictors which are dominated in \n",
        "# the error-disparity space by others from the sweep \n",
        "# (note that the disparity will only be calculated for the sensitive feature; \n",
        "# other potentially sensitive features will not be mitigated). An importance disclaimer: \n",
        "# in general, one might not want to do this, without other considerations \n",
        "# beyond the strict optimization of error and disparity (of the given sensitive feature).\n",
        "\n",
        "# for illustration purpose only, we can set the error metric to overweigh recall rate\n",
        "errors, disparities = [], []\n",
        "for m in predictors:\n",
        "\n",
        "    def classifier(X):\n",
        "        return m.predict(X)\n",
        "    \n",
        "    error = ErrorRate(costs={\"fn\": 1, \"fp\": 1./F_SCORE_BETA})  # similar to inverse of f-beta score\n",
        "    error.load_data(X_train_prep, pd.Series(y_train_prep), sensitive_features=sensitive_features_train_prep)\n",
        "    disparity = DemographicParity()\n",
        "    disparity.load_data(X_train_prep, pd.Series(y_train_prep), sensitive_features=sensitive_features_train_prep)\n",
        "\n",
        "    errors.append(error.gamma(classifier)[0])\n",
        "    disparities.append(disparity.gamma(classifier).max())\n",
        "\n",
        "    \n",
        "all_results = pd.DataFrame({\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n",
        "\n",
        "non_dominated = []\n",
        "for row in all_results.itertuples():\n",
        "    accuracy_for_lower_or_eq_disparity = all_results[\"error\"][\n",
        "        all_results[\"disparity\"] <= row.disparity\n",
        "    ]\n",
        "    if row.error <= accuracy_for_lower_or_eq_disparity.min():\n",
        "        non_dominated.append(row.predictor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1677084198612
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No matplotlib.Axes object was provided to draw on, so we create a new one\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5392ea8e0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Finally, we can evaluate the dominant models along with the unmitigated model.\n",
        "predictions = {\"unmitigated\": unmitigated_predictor.predict(X_test)}\n",
        "metric_frames = {\"unmitigated\": metric_frame}\n",
        "for model_idx in range(len(non_dominated)):\n",
        "    key = f\"dominant_model_{model_idx}\"\n",
        "    predictions[key] = non_dominated[model_idx].predict(X_test)\n",
        "\n",
        "\n",
        "plot_model_comparison(\n",
        "    x_axis_metric=partial(fbeta_score, beta=F_SCORE_BETA, zero_division=0),\n",
        "    y_axis_metric=demographic_parity_difference, \n",
        "    y_true=y_test,\n",
        "    y_preds=predictions,\n",
        "    sensitive_features=sensitive_features_test,\n",
        "    axis_labels=(\"F-beta score\", \"Demographic parity difference\"),\n",
        "    point_labels=True,\n",
        "    show_plot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1677084325632
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'ProxyNominationRFMitigated' already exists. Creating a new version of this model...\n",
            "2023/03/10 16:36:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ProxyNominationRFMitigated, version 19\n",
            "Created version '19' of model 'ProxyNominationRFMitigated'.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# upload dominant_model_0 for improvement in both demographic parity difference and F-beta scores \n",
        "model_idx = 0\n",
        "with mlflow.start_run() as run:\n",
        "    artifact_name = f\"ProxyNomination{model_label}Mitigated\"\n",
        "    mlflow.sklearn.log_model(sk_model=non_dominated[model_idx], artifact_path=artifact_name)\n",
        "    model_uri = f\"runs:/{run.info.run_id}/{artifact_name}\"\n",
        "    mlflow.register_model(model_uri=model_uri, name=artifact_name)\n",
        " "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
